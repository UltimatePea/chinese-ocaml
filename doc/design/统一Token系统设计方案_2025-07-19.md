# 骆言项目统一Token系统设计方案

## 1. 设计目标

### 1.1 主要目标
- **消除Token定义重复**：从379处重复减少到单一定义源
- **统一Token映射**：建立中央化的映射管理系统
- **简化转换逻辑**：提供统一的转换接口
- **提高可维护性**：降低新增Token的复杂度

### 1.2 设计原则
- **单一数据源**（Single Source of Truth）
- **分层架构**（Layered Architecture）
- **插件化扩展**（Plugin-based Extension）
- **向后兼容**（Backward Compatibility）

## 2. 架构设计

### 2.1 整体架构
```
┌─────────────────────────────────────────────────────────┐
│                   应用层 (Application Layer)             │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────────────┐ │
│  │   词法分析    │ │   语法分析    │ │      编译器        │ │
│  │   Lexer     │ │   Parser    │ │     Compiler       │ │
│  └─────────────┘ └─────────────┘ └─────────────────────┘ │
└─────────────────────────────────────────────────────────┘
┌─────────────────────────────────────────────────────────┐
│                   转换层 (Conversion Layer)              │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────────────┐ │
│  │  Token转换器 │ │  批量转换器   │ │     验证器         │ │
│  │  Converter  │ │ BatchConv   │ │    Validator       │ │
│  └─────────────┘ └─────────────┘ └─────────────────────┘ │
└─────────────────────────────────────────────────────────┘
┌─────────────────────────────────────────────────────────┐
│                   映射层 (Mapping Layer)                │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────────────┐ │
│  │   映射注册器  │ │   映射查找   │ │    冲突解决器       │ │
│  │  Registry   │ │   Lookup    │ │  ConflictResolver  │ │
│  └─────────────┘ └─────────────┘ └─────────────────────┘ │
└─────────────────────────────────────────────────────────┘
┌─────────────────────────────────────────────────────────┐
│                   核心层 (Core Layer)                   │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────────────┐ │
│  │  Token定义   │ │   元数据     │ │     类型系统        │ │
│  │ Definitions │ │  Metadata   │ │   Type System      │ │
│  └─────────────┘ └─────────────┘ └─────────────────────┘ │
└─────────────────────────────────────────────────────────┘
```

### 2.2 模块结构
```
src/
├── unified_token_system/
│   ├── core/
│   │   ├── token_definitions.ml      # 核心Token定义
│   │   ├── token_metadata.ml         # Token元数据
│   │   └── token_types.ml            # 类型系统
│   ├── mapping/
│   │   ├── token_registry.ml         # 映射注册器
│   │   ├── mapping_dsl.ml            # 映射DSL
│   │   └── conflict_resolver.ml      # 冲突解决
│   ├── conversion/
│   │   ├── token_converter.ml        # 统一转换器
│   │   ├── batch_converter.ml        # 批量转换
│   │   └── validator.ml              # 验证器
│   └── legacy/
│       ├── compatibility_layer.ml    # 兼容层
│       └── migration_utils.ml        # 迁移工具
```

## 3. 核心层设计

### 3.1 Token定义 (token_definitions.ml)
```ocaml
(** 统一Token定义模块 *)
module UnifiedTokenDefinitions = struct
  
  (** 基础Token标识 *)
  type token_id = string

  (** Token类别 *)
  type token_category =
    | Literal of literal_type
    | Identifier of identifier_type  
    | Keyword of keyword_type
    | Operator of operator_type
    | Delimiter of delimiter_type
    | Special of special_type

  (** 字面量类型 *)
  and literal_type =
    | IntLiteral | FloatLiteral | StringLiteral 
    | BoolLiteral | ChineseNumberLiteral | UnitLiteral

  (** 标识符类型 *)
  and identifier_type =
    | QuotedIdentifier | SpecialIdentifier 
    | ConstructorIdentifier | ModuleIdentifier | TypeIdentifier

  (** 关键字类型 *)
  and keyword_type =
    | BasicKeyword | TypeKeyword | ModuleKeyword
    | WenyanKeyword | AncientKeyword | NaturalKeyword
    | PoetryKeyword | SemanticKeyword

  (** 核心Token类型 *)
  type base_token = {
    id: token_id;
    category: token_category;
    variants: string list;  (* 不同语言形式的变体 *)
    metadata: token_metadata;
  }

  (** Token实例 *)
  and token_instance = {
    token: base_token;
    value: token_value option;
    position: position_info;
  }

  (** Token值 *)
  and token_value =
    | IntValue of int
    | FloatValue of float  
    | StringValue of string
    | BoolValue of bool
    | IdentifierValue of string

  (** 位置信息 *)
  and position_info = {
    line: int;
    column: int;
    filename: string;
    length: int;
  }
end
```

### 3.2 Token元数据 (token_metadata.ml)
```ocaml
(** Token元数据模块 *)
module TokenMetadata = struct
  
  (** 元数据类型 *)
  type metadata = {
    description: string;           (* 描述信息 *)
    chinese_variants: string list; (* 中文变体 *)
    english_equivalent: string;    (* 英文对应 *)
    priority: int;                (* 优先级 *)
    tags: string list;            (* 标签 *)
    deprecated: bool;             (* 是否废弃 *)
    since_version: string;        (* 引入版本 *)
    category_specific: category_metadata;
  }

  (** 类别特定元数据 *)
  and category_metadata =
    | LiteralMeta of literal_metadata
    | KeywordMeta of keyword_metadata
    | OperatorMeta of operator_metadata
    | DelimiterMeta of delimiter_metadata

  (** 字面量元数据 *)
  and literal_metadata = {
    numeric_base: int option;      (* 数值进制 *)
    string_delimiter: string;      (* 字符串分隔符 *)
  }

  (** 关键字元数据 *)
  and keyword_metadata = {
    language_style: language_style; (* 语言风格 *)
    scope: keyword_scope;          (* 作用域 *)
  }

  (** 语言风格 *)
  and language_style =
    | Modern          (* 现代中文 *)
    | Classical       (* 古典中文 *)
    | Wenyan         (* 文言文 *)
    | Poetry         (* 诗词 *)
    | Technical      (* 技术术语 *)

  (** 关键字作用域 *)
  and keyword_scope =
    | Global | Local | Expression | Statement | Type | Module
end
```

## 4. 映射层设计

### 4.1 映射注册器 (token_registry.ml)
```ocaml
(** 统一Token映射注册器 *)
module UnifiedTokenRegistry = struct
  
  (** 映射条目 *)
  type mapping_entry = {
    source_pattern: string;        (* 源模式 *)
    target_token: token_id;        (* 目标Token *)
    context: mapping_context;      (* 映射上下文 *)
    priority: int;                (* 优先级 *)
    conditions: condition list;    (* 条件 *)
  }

  (** 映射上下文 *)
  and mapping_context = {
    language_mode: language_mode;  (* 语言模式 *)
    scope_context: scope_context;  (* 作用域上下文 *)
  }

  (** 语言模式 *)
  and language_mode =
    | StandardMode | WenyanMode | AncientMode | PoetryMode

  (** 作用域上下文 *)
  and scope_context =
    | AnyScope 
    | ExpressionScope 
    | StatementScope 
    | TypeScope
    | ModuleScope

  (** 映射条件 *)
  and condition =
    | PrecedingToken of token_id
    | FollowingToken of token_id
    | PositionalContext of position_constraint
    | CustomPredicate of (string -> bool)

  (** 全局映射表 *)
  let global_registry = ref (Hashtbl.create 1000)

  (** 注册映射 *)
  let register_mapping entry =
    let key = (entry.source_pattern, entry.context.language_mode) in
    Hashtbl.add !global_registry key entry

  (** 批量注册 *)
  let register_batch entries =
    List.iter register_mapping entries

  (** 查找映射 *)
  let find_mapping pattern context =
    let key = (pattern, context.language_mode) in
    Hashtbl.find_opt !global_registry key

  (** 带优先级的查找 *)
  let find_best_mapping pattern context =
    Hashtbl.fold (fun (p, mode) entry acc ->
      if p = pattern && mode = context.language_mode then
        match acc with
        | None -> Some entry
        | Some current -> 
          if entry.priority > current.priority then Some entry else acc
      else acc
    ) !global_registry None
end
```

### 4.2 映射DSL (mapping_dsl.ml)
```ocaml
(** 映射定义DSL *)
module MappingDSL = struct
  
  (** DSL构造器 *)
  let (~>) source target = (source, target)
  let (@:) (source, target) priority = (source, target, priority)
  let (@|) (source, target, priority) context = (source, target, priority, context)

  (** 批量映射定义 *)
  let define_mappings name mappings =
    let entries = List.map (fun (source, target, priority, context) ->
      UnifiedTokenRegistry.{
        source_pattern = source;
        target_token = target;
        context = context;
        priority = priority;
        conditions = [];
      }
    ) mappings in
    UnifiedTokenRegistry.register_batch entries;
    Printf.printf "已注册映射集: %s (%d个映射)\n" name (List.length entries)

  (** 预定义上下文 *)
  let standard_context = UnifiedTokenRegistry.{
    language_mode = StandardMode;
    scope_context = AnyScope;
  }

  let wenyan_context = UnifiedTokenRegistry.{
    language_mode = WenyanMode;
    scope_context = AnyScope;
  }

  (** 示例映射定义 *)
  let register_basic_keywords () =
    define_mappings "基础关键字" [
      "让" ~> "LetKeyword" @: 100 @| standard_context;
      "递归" ~> "RecKeyword" @: 100 @| standard_context;
      "在" ~> "InKeyword" @: 100 @| standard_context;
      "函数" ~> "FunKeyword" @: 100 @| standard_context;
      "如果" ~> "IfKeyword" @: 100 @| standard_context;
      "那么" ~> "ThenKeyword" @: 100 @| standard_context;
      "否则" ~> "ElseKeyword" @: 100 @| standard_context;
    ]

  let register_wenyan_keywords () =
    define_mappings "文言文关键字" [
      "吾有" ~> "HaveKeyword" @: 90 @| wenyan_context;
      "一" ~> "OneKeyword" @: 90 @| wenyan_context;
      "名曰" ~> "NameKeyword" @: 90 @| wenyan_context;
      "乃" ~> "ThenGetKeyword" @: 90 @| wenyan_context;
    ]
end
```

## 5. 转换层设计

### 5.1 统一转换器 (token_converter.ml)
```ocaml
(** 统一Token转换器 *)
module UnifiedTokenConverter = struct

  (** 转换结果 *)
  type conversion_result =
    | Success of UnifiedTokenDefinitions.token_instance
    | Failure of conversion_error
    | Ambiguous of UnifiedTokenDefinitions.token_instance list

  (** 转换错误 *)
  and conversion_error =
    | NoMapping of string
    | InvalidContext of string
    | ConversionException of string * exn

  (** 转换选项 *)
  type conversion_options = {
    strict_mode: bool;             (* 严格模式 *)
    fallback_enabled: bool;        (* 启用后备方案 *)
    context_aware: bool;           (* 上下文感知 *)
    debug_mode: bool;              (* 调试模式 *)
  }

  (** 默认选项 *)
  let default_options = {
    strict_mode = false;
    fallback_enabled = true;
    context_aware = true;
    debug_mode = false;
  }

  (** 主转换函数 *)
  let convert_token ?(options=default_options) source_text context =
    try
      match UnifiedTokenRegistry.find_best_mapping source_text context with
      | Some mapping -> 
          let token = create_token_instance mapping source_text in
          if options.debug_mode then
            Printf.printf "✅ 转换成功: %s -> %s\n" source_text mapping.target_token;
          Success token
      | None ->
          if options.fallback_enabled then
            attempt_fallback_conversion source_text context
          else
            Failure (NoMapping source_text)
    with
    | exn -> Failure (ConversionException (source_text, exn))

  (** 创建Token实例 *)
  and create_token_instance mapping source_text =
    let base_token = TokenDefinitions.get_token_by_id mapping.target_token in
    let value = extract_token_value source_text base_token in
    UnifiedTokenDefinitions.{
      token = base_token;
      value = value;
      position = { line = 0; column = 0; filename = ""; length = String.length source_text };
    }

  (** 后备转换 *)
  and attempt_fallback_conversion source_text context =
    (* 尝试模糊匹配、拼音转换等后备方案 *)
    match fuzzy_match source_text with
    | Some candidates -> Ambiguous candidates
    | None -> Failure (NoMapping source_text)

  (** 批量转换 *)
  let batch_convert ?(options=default_options) token_texts context =
    List.map (convert_token ~options context) token_texts

  (** 流式转换 *)
  let stream_convert ?(options=default_options) token_stream context =
    Seq.map (convert_token ~options context) token_stream
end
```

### 5.2 验证器 (validator.ml)
```ocaml
(** Token系统验证器 *)
module TokenValidator = struct

  (** 验证结果 *)
  type validation_result = {
    is_valid: bool;
    errors: validation_error list;
    warnings: validation_warning list;
    statistics: validation_statistics;
  }

  (** 验证错误 *)
  and validation_error =
    | DuplicateMapping of string * string
    | ConflictingPriority of string * int * int
    | InvalidTokenDefinition of string * string
    | CircularDependency of string list

  (** 验证警告 *)
  and validation_warning =
    | UnusedMapping of string
    | LowPriorityMapping of string * int
    | AmbiguousPattern of string * string list

  (** 验证统计 *)
  and validation_statistics = {
    total_mappings: int;
    unique_patterns: int;
    conflicting_mappings: int;
    coverage_percentage: float;
  }

  (** 完整验证 *)
  let validate_system () =
    let errors = ref [] in
    let warnings = ref [] in
    
    (* 验证映射完整性 *)
    validate_mapping_integrity errors warnings;
    
    (* 验证优先级一致性 *)
    validate_priority_consistency errors warnings;
    
    (* 验证Token定义 *)
    validate_token_definitions errors warnings;
    
    (* 生成统计信息 *)
    let stats = generate_statistics () in
    
    {
      is_valid = List.length !errors = 0;
      errors = !errors;
      warnings = !warnings;
      statistics = stats;
    }

  (** 验证映射完整性 *)
  let validate_mapping_integrity errors warnings =
    let patterns = Hashtbl.create 100 in
    UnifiedTokenRegistry.iter_mappings (fun mapping ->
      match Hashtbl.find_opt patterns mapping.source_pattern with
      | Some existing -> 
          errors := DuplicateMapping (mapping.source_pattern, existing) :: !errors
      | None -> 
          Hashtbl.add patterns mapping.source_pattern mapping.target_token
    )

  (** 生成验证报告 *)
  let generate_report result =
    let buffer = Buffer.create 1000 in
    Buffer.add_string buffer "=== Token系统验证报告 ===\n\n";
    
    (* 总体状态 *)
    Buffer.add_string buffer (Printf.sprintf "验证状态: %s\n" 
      (if result.is_valid then "✅ 通过" else "❌ 失败"));
    
    (* 统计信息 *)
    Buffer.add_string buffer (Printf.sprintf "映射总数: %d\n" result.statistics.total_mappings);
    Buffer.add_string buffer (Printf.sprintf "唯一模式: %d\n" result.statistics.unique_patterns);
    Buffer.add_string buffer (Printf.sprintf "覆盖率: %.1f%%\n\n" result.statistics.coverage_percentage);
    
    (* 错误列表 *)
    if List.length result.errors > 0 then (
      Buffer.add_string buffer "❌ 错误:\n";
      List.iter (fun error ->
        Buffer.add_string buffer ("  - " ^ format_error error ^ "\n")
      ) result.errors;
      Buffer.add_string buffer "\n"
    );
    
    (* 警告列表 *)
    if List.length result.warnings > 0 then (
      Buffer.add_string buffer "⚠️  警告:\n";
      List.iter (fun warning ->
        Buffer.add_string buffer ("  - " ^ format_warning warning ^ "\n")
      ) result.warnings
    );
    
    Buffer.contents buffer
end
```

## 6. 兼容层设计

### 6.1 兼容层 (compatibility_layer.ml)
```ocaml
(** 向后兼容层 *)
module CompatibilityLayer = struct

  (** 旧系统接口适配器 *)
  module LegacyAdapters = struct
    
    (** Token_types模块兼容 *)
    module TokenTypes = struct
      (* 重新导出统一定义的类型 *)
      type token = UnifiedTokenDefinitions.token_instance
      type positioned_token = UnifiedTokenDefinitions.token_instance
      
      (* 兼容函数 *)
      let token_to_string token = 
        UnifiedTokenConverter.token_to_string token.UnifiedTokenDefinitions.token
      
      let is_keyword token =
        match token.UnifiedTokenDefinitions.token.category with
        | Keyword _ -> true
        | _ -> false
    end

    (** Lexer_tokens模块兼容 *)
    module LexerTokens = struct
      (* 类型别名 *)
      type token = UnifiedTokenDefinitions.token_instance
      
      (* 转换函数 *)
      let from_legacy_token legacy_token =
        (* 将旧的token类型转换为新的统一格式 *)
        convert_legacy_token legacy_token
        
      let to_legacy_token unified_token =
        (* 将统一格式转换回旧的token类型 *)
        extract_legacy_token unified_token
    end
  end

  (** 迁移辅助函数 *)
  module MigrationUtils = struct
    
    (** 批量迁移Token定义 *)
    let migrate_token_definitions old_definitions =
      List.map convert_old_definition old_definitions
    
    (** 验证迁移结果 *)
    let validate_migration old_tokens new_tokens =
      let old_count = List.length old_tokens in
      let new_count = List.length new_tokens in
      
      if old_count = new_count then
        Printf.printf "✅ 迁移成功: %d个Token已迁移\n" new_count
      else
        Printf.printf "⚠️  迁移警告: 原有%d个Token，迁移后%d个Token\n" old_count new_count
  end

  (** 平滑过渡支持 *)
  let enable_legacy_support () =
    (* 注册旧系统的映射 *)
    register_legacy_mappings ();
    
    (* 启用兼容模式 *)
    UnifiedTokenConverter.set_compatibility_mode true;
    
    Printf.printf "✅ 已启用向后兼容支持\n"
    
  let disable_legacy_support () =
    (* 清理旧系统映射 *)
    cleanup_legacy_mappings ();
    
    (* 禁用兼容模式 *)
    UnifiedTokenConverter.set_compatibility_mode false;
    
    Printf.printf "ℹ️  已禁用向后兼容支持\n"
end
```

## 7. 实施计划

### 7.1 第一阶段：核心系统构建 (第1-2周)
1. **实现核心Token定义系统**
   - 创建 `unified_token_system/core/` 模块
   - 定义基础数据结构
   - 实现元数据系统

2. **实现映射注册器**
   - 创建 `unified_token_system/mapping/` 模块
   - 实现DSL语言
   - 构建冲突解决机制

### 7.2 第二阶段：转换系统开发 (第3-4周)
1. **实现统一转换器**
   - 创建 `unified_token_system/conversion/` 模块
   - 实现批量转换功能
   - 添加验证机制

2. **构建兼容层**
   - 创建 `unified_token_system/legacy/` 模块
   - 实现旧系统适配器
   - 提供迁移工具

### 7.3 第三阶段：集成和测试 (第5-6周)
1. **系统集成**
   - 将新系统集成到现有代码库
   - 逐步替换旧的Token处理逻辑
   - 保持向后兼容性

2. **全面测试**
   - 单元测试覆盖
   - 集成测试
   - 性能测试
   - 回归测试

### 7.4 第四阶段：优化和清理 (第7-8周)
1. **性能优化**
   - 查找性能瓶颈
   - 优化映射查找算法
   - 缓存机制优化

2. **代码清理**
   - 删除重复代码
   - 更新文档
   - 重构相关模块

## 8. 预期效果

### 8.1 定量指标
- **重复代码减少**: 从379处减少到约50处 (87%减少)
- **维护成本降低**: 新增Token从需要修改8个文件减少到2个文件
- **编译时间优化**: 预计减少30-40%
- **代码行数减少**: 预计减少约3000行重复代码

### 8.2 定性改善
- **代码质量提升**: 统一的架构和清晰的职责分离
- **开发效率提高**: 新功能开发更加便捷
- **错误率降低**: 减少由重复代码导致的不一致错误
- **团队协作改善**: 清晰的模块界面便于并行开发

## 9. 结论

统一Token系统的设计将从根本上解决当前项目中Token定义重复的问题，通过分层架构和插件化设计，不仅能够满足当前需求，还为未来的功能扩展奠定了良好的基础。建议按照提出的四阶段计划实施，确保平滑过渡和最小化对现有功能的影响。