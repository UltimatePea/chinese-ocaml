(** éª†è¨€ç»Ÿä¸€Tokenæ³¨å†Œç³»ç»Ÿç»¼åˆæµ‹è¯•

    æœ¬æµ‹è¯•æ¨¡å—æä¾›å¯¹ unified_token_registry.ml çš„å…¨é¢æµ‹è¯•è¦†ç›–ã€‚

    æŠ€æœ¯å€ºåŠ¡æ”¹è¿›ï¼šæµ‹è¯•è¦†ç›–ç‡ç³»ç»Ÿæ€§æå‡è®¡åˆ’ - ç¬¬å››é˜¶æ®µæ ¸å¿ƒç»„ä»¶æ¶æ„ä¼˜åŒ– - Fix #954
    @author éª†è¨€AIä»£ç†
    @version 1.0
    @since 2025-07-23 *)

open Alcotest
open Yyocamlc_lib
open Unified_token_registry

(** ==================== æµ‹è¯•è¾…åŠ©å‡½æ•° ==================== *)

(** åˆ›å»ºæµ‹è¯•ç”¨çš„æ˜ å°„æ¡ç›® *)
let create_test_entry source target priority category enabled =
  { source; target; priority; category; enabled }

(** æ¸…ç†æ³¨å†Œè¡¨çŠ¶æ€ *)
let cleanup_registry () =
  TokenRegistry.clear_all_mappings ();
  ()

(** ==================== æ˜ å°„æ¡ç›®ç»“æ„æµ‹è¯• ==================== *)

(** æµ‹è¯•æ˜ å°„æ¡ç›®çš„åˆ›å»ºå’Œè®¿é—® *)
let test_mapping_entry_creation () =
  let entry = create_test_entry "æµ‹è¯•" Unified_token_core.Identifier 1 "æ ‡è¯†ç¬¦" true in

  check string "æºå­—ç¬¦ä¸²æ­£ç¡®" "æµ‹è¯•" entry.source;
  check (module Unified_token_core) "ç›®æ ‡tokenæ­£ç¡®" Unified_token_core.Identifier entry.target;
  check int "ä¼˜å…ˆçº§æ­£ç¡®" 1 entry.priority;
  check string "åˆ†ç±»æ­£ç¡®" "æ ‡è¯†ç¬¦" entry.category;
  check bool "å¯ç”¨çŠ¶æ€æ­£ç¡®" true entry.enabled;
  ()

(** æµ‹è¯•ä¸åŒä¼˜å…ˆçº§çš„æ˜ å°„æ¡ç›® *)
let test_priority_levels () =
  let high_priority = create_test_entry "é«˜" Unified_token_core.Keyword 1 "å…³é”®å­—" true in
  let medium_priority = create_test_entry "ä¸­" Unified_token_core.Operator 2 "è¿ç®—ç¬¦" true in
  let low_priority = create_test_entry "ä½" Unified_token_core.Delimiter 3 "åˆ†éš”ç¬¦" true in

  check bool "é«˜ä¼˜å…ˆçº§è®¾ç½®" true (high_priority.priority = 1);
  check bool "ä¸­ä¼˜å…ˆçº§è®¾ç½®" true (medium_priority.priority = 2);
  check bool "ä½ä¼˜å…ˆçº§è®¾ç½®" true (low_priority.priority = 3);

  (* æµ‹è¯•ä¼˜å…ˆçº§æ¯”è¾ƒ *)
  check bool "é«˜ä¼˜å…ˆçº§å¤§äºä¸­ä¼˜å…ˆçº§" true (high_priority.priority < medium_priority.priority);
  check bool "ä¸­ä¼˜å…ˆçº§å¤§äºä½ä¼˜å…ˆçº§" true (medium_priority.priority < low_priority.priority);
  ()

(** ==================== Tokenæ³¨å†Œè¡¨åŸºç¡€åŠŸèƒ½æµ‹è¯• ==================== *)

(** æµ‹è¯•å•ä¸ªæ˜ å°„çš„æ³¨å†Œ *)
let test_single_mapping_registration () =
  cleanup_registry ();

  let entry = create_test_entry "è®©" Unified_token_core.Keyword 1 "å…³é”®å­—" true in
  TokenRegistry.register_mapping entry;

  let lookup_result = TokenRegistry.lookup_token "è®©" in
  (match lookup_result with
  | Some found_entry ->
      check string "æŸ¥æ‰¾ç»“æœæºå­—ç¬¦ä¸²" "è®©" found_entry.source;
      check (module Unified_token_core) "æŸ¥æ‰¾ç»“æœç›®æ ‡token" Unified_token_core.Keyword found_entry.target
  | None -> fail "åº”è¯¥èƒ½æ‰¾åˆ°æ³¨å†Œçš„æ˜ å°„");
  ()

(** æµ‹è¯•å¤šä¸ªæ˜ å°„çš„æ³¨å†Œ *)
let test_multiple_mapping_registration () =
  cleanup_registry ();

  let entries =
    [
      create_test_entry "å¦‚æœ" Unified_token_core.Keyword 1 "æ§åˆ¶ç»“æ„" true;
      create_test_entry "é‚£ä¹ˆ" Unified_token_core.Keyword 1 "æ§åˆ¶ç»“æ„" true;
      create_test_entry "å¦åˆ™" Unified_token_core.Keyword 1 "æ§åˆ¶ç»“æ„" true;
      create_test_entry "åŠ " Unified_token_core.Operator 2 "ç®—æœ¯è¿ç®—" true;
      create_test_entry "å‡" Unified_token_core.Operator 2 "ç®—æœ¯è¿ç®—" true;
    ]
  in

  List.iter TokenRegistry.register_mapping entries;

  (* éªŒè¯æ‰€æœ‰æ˜ å°„éƒ½èƒ½è¢«æ‰¾åˆ° *)
  List.iter
    (fun entry ->
      let lookup_result = TokenRegistry.lookup_token entry.source in
      match lookup_result with
      | Some found_entry -> check string ("æŸ¥æ‰¾" ^ entry.source) entry.source found_entry.source
      | None -> fail ("æ— æ³•æ‰¾åˆ°æ˜ å°„: " ^ entry.source))
    entries;
  ()

(** ==================== TokenæŸ¥æ‰¾åŠŸèƒ½æµ‹è¯• ==================== *)

(** æµ‹è¯•åŸºæœ¬çš„tokenæŸ¥æ‰¾ *)
let test_basic_token_lookup () =
  cleanup_registry ();

  let test_entry = create_test_entry "å˜é‡" Unified_token_core.Identifier 1 "å˜é‡å" true in
  TokenRegistry.register_mapping test_entry;

  let found = TokenRegistry.lookup_token "å˜é‡" in
  (match found with
  | Some entry ->
      check string "æ‰¾åˆ°çš„æºå­—ç¬¦ä¸²" "å˜é‡" entry.source;
      check (module Unified_token_core) "æ‰¾åˆ°çš„tokenç±»å‹" Unified_token_core.Identifier entry.target
  | None -> fail "åº”è¯¥æ‰¾åˆ°å·²æ³¨å†Œçš„token");

  (* æµ‹è¯•æŸ¥æ‰¾ä¸å­˜åœ¨çš„token *)
  let not_found = TokenRegistry.lookup_token "ä¸å­˜åœ¨çš„token" in
  check (option (module Unified_token_registry)) "ä¸å­˜åœ¨çš„tokenæŸ¥æ‰¾ç»“æœ" None not_found;
  ()

(** æµ‹è¯•ä¼˜å…ˆçº§å½±å“æŸ¥æ‰¾ç»“æœ *)
let test_priority_based_lookup () =
  cleanup_registry ();

  (* æ³¨å†ŒåŒä¸€ä¸ªæºå­—ç¬¦ä¸²çš„å¤šä¸ªæ˜ å°„ï¼Œä¸åŒä¼˜å…ˆçº§ *)
  let high_priority_entry = create_test_entry "æµ‹è¯•" Unified_token_core.Keyword 1 "å…³é”®å­—" true in
  let low_priority_entry = create_test_entry "æµ‹è¯•" Unified_token_core.Identifier 3 "æ ‡è¯†ç¬¦" true in

  TokenRegistry.register_mapping low_priority_entry;
  TokenRegistry.register_mapping high_priority_entry;

  let lookup_result = TokenRegistry.lookup_token "æµ‹è¯•" in
  (match lookup_result with
  | Some found_entry ->
      (* åº”è¯¥è¿”å›é«˜ä¼˜å…ˆçº§çš„æ¡ç›® *)
      check int "åº”è¯¥è¿”å›é«˜ä¼˜å…ˆçº§æ¡ç›®" 1 found_entry.priority;
      check (module Unified_token_core) "åº”è¯¥æ˜¯å…³é”®å­—ç±»å‹" Unified_token_core.Keyword found_entry.target
  | None -> fail "åº”è¯¥æ‰¾åˆ°ä¼˜å…ˆçº§æœ€é«˜çš„æ˜ å°„");
  ()

(** ==================== åå‘æŸ¥æ‰¾åŠŸèƒ½æµ‹è¯• ==================== *)

(** æµ‹è¯•åå‘TokenæŸ¥æ‰¾ *)
let test_reverse_token_lookup () =
  cleanup_registry ();

  let entries =
    [
      create_test_entry "å¦‚æœ" Unified_token_core.Keyword 1 "æ§åˆ¶ç»“æ„" true;
      create_test_entry "å‡å¦‚" Unified_token_core.Keyword 1 "æ§åˆ¶ç»“æ„" true;
      create_test_entry "è‹¥" Unified_token_core.Keyword 1 "æ§åˆ¶ç»“æ„" true;
    ]
  in

  List.iter TokenRegistry.register_mapping entries;

  let reverse_result = TokenRegistry.reverse_lookup Unified_token_core.Keyword in
  let expected_sources = [ "å¦‚æœ"; "å‡å¦‚"; "è‹¥" ] in

  (* éªŒè¯åå‘æŸ¥æ‰¾ç»“æœåŒ…å«æ‰€æœ‰æœŸæœ›çš„æºå­—ç¬¦ä¸² *)
  List.iter
    (fun expected_source ->
      check bool ("åå‘æŸ¥æ‰¾åŒ…å«: " ^ expected_source) true (List.mem expected_source reverse_result))
    expected_sources;
  ()

(** ==================== æ˜ å°„å¯ç”¨çŠ¶æ€ç®¡ç†æµ‹è¯• ==================== *)

(** æµ‹è¯•å¯ç”¨å’Œç¦ç”¨æ˜ å°„ *)
let test_enable_disable_mappings () =
  cleanup_registry ();

  let disabled_entry = create_test_entry "ç¦ç”¨" Unified_token_core.Keyword 1 "æµ‹è¯•" false in
  let enabled_entry = create_test_entry "å¯ç”¨" Unified_token_core.Keyword 1 "æµ‹è¯•" true in

  TokenRegistry.register_mapping disabled_entry;
  TokenRegistry.register_mapping enabled_entry;

  (* æŸ¥æ‰¾ç¦ç”¨çš„æ˜ å°„ *)
  let disabled_result = TokenRegistry.lookup_token "ç¦ç”¨" in
  check (option (module Unified_token_registry)) "ç¦ç”¨çš„æ˜ å°„ä¸åº”è¢«æ‰¾åˆ°" None disabled_result;

  (* æŸ¥æ‰¾å¯ç”¨çš„æ˜ å°„ *)
  let enabled_result = TokenRegistry.lookup_token "å¯ç”¨" in
  (match enabled_result with
  | Some found_entry -> check bool "å¯ç”¨çš„æ˜ å°„åº”è¯¥è¢«æ‰¾åˆ°" true found_entry.enabled
  | None -> fail "å¯ç”¨çš„æ˜ å°„åº”è¯¥èƒ½è¢«æ‰¾åˆ°");
  ()

(** æµ‹è¯•åŠ¨æ€å¯ç”¨å’Œç¦ç”¨ *)
let test_dynamic_enable_disable () =
  cleanup_registry ();

  let test_entry = create_test_entry "åŠ¨æ€æµ‹è¯•" Unified_token_core.Identifier 1 "æµ‹è¯•" true in
  TokenRegistry.register_mapping test_entry;

  (* åˆå§‹çŠ¶æ€åº”è¯¥èƒ½æ‰¾åˆ° *)
  let initial_result = TokenRegistry.lookup_token "åŠ¨æ€æµ‹è¯•" in
  check bool "åˆå§‹çŠ¶æ€åº”è¯¥èƒ½æ‰¾åˆ°" true (initial_result <> None);

  (* ç¦ç”¨æ˜ å°„ *)
  TokenRegistry.disable_mapping "åŠ¨æ€æµ‹è¯•";
  let disabled_result = TokenRegistry.lookup_token "åŠ¨æ€æµ‹è¯•" in
  check (option (module Unified_token_registry)) "ç¦ç”¨åä¸åº”æ‰¾åˆ°" None disabled_result;

  (* é‡æ–°å¯ç”¨æ˜ å°„ *)
  TokenRegistry.enable_mapping "åŠ¨æ€æµ‹è¯•";
  let reenabled_result = TokenRegistry.lookup_token "åŠ¨æ€æµ‹è¯•" in
  check bool "é‡æ–°å¯ç”¨ååº”è¯¥èƒ½æ‰¾åˆ°" true (reenabled_result <> None);
  ()

(** ==================== åˆ†ç±»ç®¡ç†åŠŸèƒ½æµ‹è¯• ==================== *)

(** æµ‹è¯•æŒ‰åˆ†ç±»æŸ¥æ‰¾æ˜ å°„ *)
let test_category_based_lookup () =
  cleanup_registry ();

  let keyword_entries =
    [
      create_test_entry "è®©" Unified_token_core.Keyword 1 "å£°æ˜å…³é”®å­—" true;
      create_test_entry "å‡½æ•°" Unified_token_core.Keyword 1 "å£°æ˜å…³é”®å­—" true;
    ]
  in

  let operator_entries =
    [
      create_test_entry "åŠ " Unified_token_core.Operator 2 "ç®—æœ¯è¿ç®—ç¬¦" true;
      create_test_entry "ä¹˜" Unified_token_core.Operator 2 "ç®—æœ¯è¿ç®—ç¬¦" true;
    ]
  in

  List.iter TokenRegistry.register_mapping (keyword_entries @ operator_entries);

  let declaration_keywords = TokenRegistry.lookup_by_category "å£°æ˜å…³é”®å­—" in
  check int "å£°æ˜å…³é”®å­—æ•°é‡" 2 (List.length declaration_keywords);

  let arithmetic_operators = TokenRegistry.lookup_by_category "ç®—æœ¯è¿ç®—ç¬¦" in
  check int "ç®—æœ¯è¿ç®—ç¬¦æ•°é‡" 2 (List.length arithmetic_operators);

  let nonexistent_category = TokenRegistry.lookup_by_category "ä¸å­˜åœ¨çš„åˆ†ç±»" in
  check int "ä¸å­˜åœ¨åˆ†ç±»çš„ç»“æœ" 0 (List.length nonexistent_category);
  ()

(** ==================== æ‰¹é‡æ“ä½œåŠŸèƒ½æµ‹è¯• ==================== *)

(** æµ‹è¯•æ‰¹é‡æ³¨å†Œæ˜ å°„ *)
let test_batch_registration () =
  cleanup_registry ();

  let batch_entries =
    [
      create_test_entry "ç¬¬ä¸€" Unified_token_core.Keyword 1 "æµ‹è¯•" true;
      create_test_entry "ç¬¬äºŒ" Unified_token_core.Operator 2 "æµ‹è¯•" true;
      create_test_entry "ç¬¬ä¸‰" Unified_token_core.Delimiter 3 "æµ‹è¯•" true;
      create_test_entry "ç¬¬å››" Unified_token_core.Identifier 1 "æµ‹è¯•" true;
    ]
  in

  TokenRegistry.register_batch batch_entries;

  (* éªŒè¯æ‰€æœ‰æ¡ç›®éƒ½å·²æ³¨å†Œ *)
  List.iter
    (fun entry ->
      let lookup_result = TokenRegistry.lookup_token entry.source in
      check bool ("æ‰¹é‡æ³¨å†ŒéªŒè¯: " ^ entry.source) true (lookup_result <> None))
    batch_entries;
  ()

(** æµ‹è¯•æ‰¹é‡æ¸…ç†åŠŸèƒ½ *)
let test_batch_cleanup () =
  cleanup_registry ();

  let test_entries =
    [
      create_test_entry "æ¸…ç†1" Unified_token_core.Keyword 1 "æµ‹è¯•" true;
      create_test_entry "æ¸…ç†2" Unified_token_core.Operator 2 "æµ‹è¯•" true;
    ]
  in

  List.iter TokenRegistry.register_mapping test_entries;

  (* éªŒè¯æ¡ç›®å·²å­˜åœ¨ *)
  List.iter
    (fun entry ->
      let lookup_result = TokenRegistry.lookup_token entry.source in
      check bool ("æ¸…ç†å‰éªŒè¯: " ^ entry.source) true (lookup_result <> None))
    test_entries;

  (* æ¸…ç†æ‰€æœ‰æ˜ å°„ *)
  TokenRegistry.clear_all_mappings ();

  (* éªŒè¯æ¡ç›®å·²è¢«æ¸…ç† *)
  List.iter
    (fun entry ->
      let lookup_result = TokenRegistry.lookup_token entry.source in
      check (option (module Unified_token_registry)) ("æ¸…ç†åéªŒè¯: " ^ entry.source) None lookup_result)
    test_entries;
  ()

(** ==================== é”™è¯¯å¤„ç†å’Œè¾¹ç•Œæµ‹è¯• ==================== *)

(** æµ‹è¯•ç©ºå­—ç¬¦ä¸²å¤„ç† *)
let test_empty_string_handling () =
  cleanup_registry ();

  (* æµ‹è¯•ç©ºå­—ç¬¦ä¸²ä½œä¸ºæº *)
  let empty_source_entry = create_test_entry "" Unified_token_core.Identifier 1 "ç©ºå­—ç¬¦ä¸²" true in
  TokenRegistry.register_mapping empty_source_entry;

  let empty_lookup = TokenRegistry.lookup_token "" in
  (match empty_lookup with
  | Some found_entry -> check string "ç©ºå­—ç¬¦ä¸²æ˜ å°„æºå­—ç¬¦ä¸²" "" found_entry.source
  | None ->
      (* ç©ºå­—ç¬¦ä¸²å¯èƒ½è¢«æ‹’ç»æ³¨å†Œï¼Œè¿™æ˜¯å¯ä»¥æ¥å—çš„ *)
      check bool "ç©ºå­—ç¬¦ä¸²å¤„ç†ï¼ˆå¯é€‰ï¼‰" true true);

  (* æµ‹è¯•æŸ¥æ‰¾ç©ºå­—ç¬¦ä¸² *)
  let empty_query = TokenRegistry.lookup_token "" in
  ignore empty_query;
  (* ä¸ç®¡ç»“æœå¦‚ä½•éƒ½æ˜¯å¯ä»¥æ¥å—çš„ *)
  ()

(** æµ‹è¯•Unicodeå­—ç¬¦å¤„ç† *)
let test_unicode_character_handling () =
  cleanup_registry ();

  let unicode_entries =
    [
      create_test_entry "ğŸ˜€" Unified_token_core.Identifier 1 "è¡¨æƒ…ç¬¦å·" true;
      create_test_entry "Î±" Unified_token_core.Identifier 1 "å¸Œè…Šå­—æ¯" true;
      create_test_entry "ä¸­æ–‡" Unified_token_core.Keyword 1 "ä¸­æ–‡å­—ç¬¦" true;
      create_test_entry "æ—¥æœ¬èª" Unified_token_core.Identifier 1 "æ—¥æ–‡å­—ç¬¦" true;
    ]
  in

  List.iter TokenRegistry.register_mapping unicode_entries;

  (* éªŒè¯Unicodeå­—ç¬¦èƒ½æ­£ç¡®å¤„ç† *)
  List.iter
    (fun entry ->
      let lookup_result = TokenRegistry.lookup_token entry.source in
      check bool ("Unicodeå¤„ç†: " ^ entry.source) true (lookup_result <> None))
    unicode_entries;
  ()

(** æµ‹è¯•é•¿å­—ç¬¦ä¸²å¤„ç† *)
let test_long_string_handling () =
  cleanup_registry ();

  let long_string = String.make 1000 'a' in
  let long_entry = create_test_entry long_string Unified_token_core.Identifier 1 "é•¿å­—ç¬¦ä¸²" true in

  TokenRegistry.register_mapping long_entry;

  let long_lookup = TokenRegistry.lookup_token long_string in
  check bool "é•¿å­—ç¬¦ä¸²å¤„ç†" true (long_lookup <> None);
  ()

(** ==================== æ€§èƒ½æµ‹è¯• ==================== *)

(** æµ‹è¯•å¤§é‡æ˜ å°„çš„æ€§èƒ½ *)
let test_large_scale_performance () =
  cleanup_registry ();

  (* æ³¨å†Œå¤§é‡æ˜ å°„ *)
  for i = 1 to 1000 do
    let entry =
      create_test_entry ("æµ‹è¯•" ^ string_of_int i) Unified_token_core.Identifier 1 "æ€§èƒ½æµ‹è¯•" true
    in
    TokenRegistry.register_mapping entry
  done;

  (* æµ‹è¯•æŸ¥æ‰¾æ€§èƒ½ *)
  for i = 1 to 100 do
    let query = "æµ‹è¯•" ^ string_of_int (i * 10) in
    let result = TokenRegistry.lookup_token query in
    check bool ("å¤§è§„æ¨¡æŸ¥æ‰¾: " ^ query) true (result <> None)
  done;

  check bool "å¤§è§„æ¨¡æ€§èƒ½æµ‹è¯•å®Œæˆ" true true;
  ()

(** ==================== æµ‹è¯•å¥—ä»¶å®šä¹‰ ==================== *)

let mapping_entry_tests =
  [
    test_case "æ˜ å°„æ¡ç›®åˆ›å»ºæµ‹è¯•" `Quick test_mapping_entry_creation;
    test_case "ä¼˜å…ˆçº§å±‚æ¬¡æµ‹è¯•" `Quick test_priority_levels;
  ]

let basic_registry_tests =
  [
    test_case "å•ä¸ªæ˜ å°„æ³¨å†Œæµ‹è¯•" `Quick test_single_mapping_registration;
    test_case "å¤šä¸ªæ˜ å°„æ³¨å†Œæµ‹è¯•" `Quick test_multiple_mapping_registration;
  ]

let lookup_tests =
  [
    test_case "åŸºç¡€tokenæŸ¥æ‰¾æµ‹è¯•" `Quick test_basic_token_lookup;
    test_case "ä¼˜å…ˆçº§æŸ¥æ‰¾æµ‹è¯•" `Quick test_priority_based_lookup;
    test_case "åå‘æŸ¥æ‰¾æµ‹è¯•" `Quick test_reverse_token_lookup;
  ]

let state_management_tests =
  [
    test_case "å¯ç”¨ç¦ç”¨æ˜ å°„æµ‹è¯•" `Quick test_enable_disable_mappings;
    test_case "åŠ¨æ€å¯ç”¨ç¦ç”¨æµ‹è¯•" `Quick test_dynamic_enable_disable;
  ]

let category_tests = [ test_case "åˆ†ç±»æŸ¥æ‰¾æµ‹è¯•" `Quick test_category_based_lookup ]

let batch_operation_tests =
  [
    test_case "æ‰¹é‡æ³¨å†Œæµ‹è¯•" `Quick test_batch_registration; test_case "æ‰¹é‡æ¸…ç†æµ‹è¯•" `Quick test_batch_cleanup;
  ]

let edge_case_tests =
  [
    test_case "ç©ºå­—ç¬¦ä¸²å¤„ç†æµ‹è¯•" `Quick test_empty_string_handling;
    test_case "Unicodeå­—ç¬¦å¤„ç†æµ‹è¯•" `Quick test_unicode_character_handling;
    test_case "é•¿å­—ç¬¦ä¸²å¤„ç†æµ‹è¯•" `Quick test_long_string_handling;
  ]

let performance_tests = [ test_case "å¤§è§„æ¨¡æ€§èƒ½æµ‹è¯•" `Quick test_large_scale_performance ]

(** ä¸»æµ‹è¯•è¿è¡Œå™¨ *)
let () =
  run "Unified_token_registry ç»¼åˆæµ‹è¯•"
    [
      ("æ˜ å°„æ¡ç›®ç»“æ„", mapping_entry_tests);
      ("åŸºç¡€æ³¨å†ŒåŠŸèƒ½", basic_registry_tests);
      ("æŸ¥æ‰¾åŠŸèƒ½", lookup_tests);
      ("çŠ¶æ€ç®¡ç†", state_management_tests);
      ("åˆ†ç±»ç®¡ç†", category_tests);
      ("æ‰¹é‡æ“ä½œ", batch_operation_tests);
      ("è¾¹ç•Œæƒ…å†µ", edge_case_tests);
      ("æ€§èƒ½æµ‹è¯•", performance_tests);
    ]
