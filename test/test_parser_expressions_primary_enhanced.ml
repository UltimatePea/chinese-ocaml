(** è§£æå™¨åŸºç¡€è¡¨è¾¾å¼æ¨¡å—å¢å¼ºæµ‹è¯• - Phase 25 æµ‹è¯•è¦†ç›–ç‡æå‡
    
    æœ¬æµ‹è¯•æ¨¡å—ä¸“é—¨é’ˆå¯¹ parser_expressions_primary.ml è¿›è¡Œå…¨é¢æµ‹è¯•ï¼Œ
    è¦†ç›–å„ç§è¡¨è¾¾å¼è§£æåœºæ™¯ï¼ŒåŒ…æ‹¬è¾¹ç•Œæ¡ä»¶å’Œé”™è¯¯å¤„ç†ã€‚
    
    æµ‹è¯•è¦†ç›–èŒƒå›´ï¼š
    - åŸºç¡€è¡¨è¾¾å¼è§£æï¼ˆå­—é¢é‡ã€æ ‡è¯†ç¬¦ã€å…³é”®å­—ï¼‰
    - åç¼€è¡¨è¾¾å¼ï¼ˆå­—æ®µè®¿é—®ã€æ•°ç»„è®¿é—®ï¼‰
    - å¤åˆè¡¨è¾¾å¼ï¼ˆæ‹¬å·è¡¨è¾¾å¼ã€å‡½æ•°è°ƒç”¨ï¼‰
    - è¯—è¯è¡¨è¾¾å¼ï¼ˆä¸­æ–‡å­—ç¬¦ã€è¯—è¯è¯­æ³•ï¼‰
    - é”™è¯¯å¤„ç†å’Œè¾¹ç•Œæ¡ä»¶
    - Unicodeå­—ç¬¦å¤„ç†
    
    @author éª†è¨€æŠ€æœ¯å€ºåŠ¡æ¸…ç†å›¢é˜Ÿ - Phase 25
    @version 1.0
    @since 2025-07-20 Issue #678 æ ¸å¿ƒæ¨¡å—æµ‹è¯•è¦†ç›–ç‡æå‡ *)

open Alcotest
open Yyocamlc_lib.Ast
open Yyocamlc_lib.Lexer
open Yyocamlc_lib.Parser
open Yyocamlc_lib.Parser_expressions_primary

(** åˆ›å»ºæµ‹è¯•ç”¨çš„è§£æå™¨çŠ¶æ€ *)
let create_test_state tokens =
  create_parser_state tokens

(** åŸºç¡€è¡¨è¾¾å¼è§£ææµ‹è¯• *)
module BasicExpressionTests = struct
  
  (** æµ‹è¯•æ•´æ•°å­—é¢é‡è§£æ *)
  let test_integer_literal () =
    let tokens = [
      (IntToken 42, { line = 1; column = 1; filename = "test" });
      (EOF, { line = 1; column = 3; filename = "test" });
    ] in
    let state = create_test_state tokens in
    let expr, _ = parse_primary_expr state in
    check (testable pp_expr equal_expr) "æ•´æ•°å­—é¢é‡è§£æ" (LitExpr (IntLit 42)) expr

  (** æµ‹è¯•æµ®ç‚¹æ•°å­—é¢é‡è§£æ *)
  let test_float_literal () =
    let tokens = [
      (FloatToken 3.14, { line = 1; column = 1; filename = "test" });
      (EOF, { line = 1; column = 5; filename = "test" });
    ] in
    let state = create_test_state tokens in
    let expr, _ = parse_primary_expr state in
    check (testable pp_expr equal_expr) "æµ®ç‚¹æ•°å­—é¢é‡è§£æ" (LitExpr (FloatLit 3.14)) expr

  (** æµ‹è¯•å­—ç¬¦ä¸²å­—é¢é‡è§£æ *)
  let test_string_literal () =
    let tokens = [
      (StringToken "ä½ å¥½ä¸–ç•Œ", { line = 1; column = 1; filename = "test" });
      (EOF, { line = 1; column = 6; filename = "test" });
    ] in
    let state = create_test_state tokens in
    let expr, _ = parse_primary_expr state in
    check (testable pp_expr equal_expr) "ä¸­æ–‡å­—ç¬¦ä¸²å­—é¢é‡è§£æ" (LitExpr (StringLit "ä½ å¥½ä¸–ç•Œ")) expr

  (** æµ‹è¯•å¸ƒå°”å­—é¢é‡è§£æ *)
  let test_boolean_literals () =
    (* æµ‹è¯• true *)
    let tokens_true = [
      (BoolToken true, { line = 1; column = 1; filename = "test" });
      (EOF, { line = 1; column = 5; filename = "test" });
    ] in
    let state_true = create_test_state tokens_true in
    let expr_true, _ = parse_primary_expr state_true in
    check (testable pp_expr equal_expr) "å¸ƒå°” true è§£æ" (LitExpr (BoolLit true)) expr_true;
    
    (* æµ‹è¯• false *)
    let tokens_false = [
      (BoolToken false, { line = 1; column = 1; filename = "test" });
      (EOF, { line = 1; column = 6; filename = "test" });
    ] in
    let state_false = create_test_state tokens_false in
    let expr_false, _ = parse_primary_expr state_false in
    check (testable pp_expr equal_expr) "å¸ƒå°” false è§£æ" (LitExpr (BoolLit false)) expr_false

  (** æµ‹è¯•æ ‡è¯†ç¬¦è§£æ *)
  let test_identifier_parsing () =
    let test_cases = [
      ("x", "ç®€å•æ ‡è¯†ç¬¦");
      ("å˜é‡å", "ä¸­æ–‡æ ‡è¯†ç¬¦");
      ("var_123", "å¸¦æ•°å­—æ ‡è¯†ç¬¦");
      ("è¯—è¯_è§£æå™¨", "ä¸­è‹±æ··åˆæ ‡è¯†ç¬¦");
    ] in
    List.iter (fun (id, desc) ->
      let tokens = [
        (QuotedIdentifierToken id, { line = 1; column = 1; filename = "test" });
        (EOF, { line = 1; column = (String.length id + 1); filename = "test" });
      ] in
      let state = create_test_state tokens in
      let expr, _ = parse_primary_expr state in
      check (testable pp_expr equal_expr) desc (VarExpr id) expr
    ) test_cases

end

(** åç¼€è¡¨è¾¾å¼æµ‹è¯• *)
module PostfixExpressionTests = struct

  (** æµ‹è¯•å­—æ®µè®¿é—® *)
  let test_field_access () =
    let tokens = [
      (QuotedIdentifierToken "obj", { line = 1; column = 1; filename = "test" });
      (Dot, { line = 1; column = 4; filename = "test" });
      (QuotedIdentifierToken "field", { line = 1; column = 5; filename = "test" });
      (EOF, { line = 1; column = 10; filename = "test" });
    ] in
    let state = create_test_state tokens in
    let base_expr = VarExpr "obj" in
    let expr, _ = parse_postfix_expr base_expr state in
    check (testable pp_expr equal_expr) "å­—æ®µè®¿é—®è§£æ" (FieldAccessExpr (VarExpr "obj", "field")) expr

  (** æµ‹è¯•å¤šçº§å­—æ®µè®¿é—® *)
  let test_nested_field_access () =
    let tokens = [
      (QuotedIdentifierToken "å¯¹è±¡", { line = 1; column = 1; filename = "test" });
      (Dot, { line = 1; column = 3; filename = "test" });
      (QuotedIdentifierToken "å±æ€§1", { line = 1; column = 4; filename = "test" });
      (Dot, { line = 1; column = 7; filename = "test" });
      (QuotedIdentifierToken "å±æ€§2", { line = 1; column = 8; filename = "test" });
      (EOF, { line = 1; column = 11; filename = "test" });
    ] in
    let state = create_test_state tokens in
    let base_expr = VarExpr "å¯¹è±¡" in
    let expr, _ = parse_postfix_expr base_expr state in
    let expected = FieldAccessExpr (FieldAccessExpr (VarExpr "å¯¹è±¡", "å±æ€§1"), "å±æ€§2") in
    check (testable pp_expr equal_expr) "å¤šçº§å­—æ®µè®¿é—®è§£æ" expected expr

  (** æµ‹è¯•æ•°ç»„è®¿é—® *)
  let test_array_access () =
    let tokens = [
      (QuotedIdentifierToken "arr", { line = 1; column = 1; filename = "test" });
      (LeftBracket, { line = 1; column = 4; filename = "test" });
      (IntToken 0, { line = 1; column = 5; filename = "test" });
      (RightBracket, { line = 1; column = 6; filename = "test" });
      (EOF, { line = 1; column = 7; filename = "test" });
    ] in
    let state = create_test_state tokens in
    let base_expr = VarExpr "arr" in
    let expr, _ = parse_postfix_expr base_expr state in
    check (testable pp_expr equal_expr) "æ•°ç»„è®¿é—®è§£æ" 
      (ArrayAccessExpr (VarExpr "arr", LitExpr (IntLit 0))) expr

  (** æµ‹è¯•ä¸­æ–‡æ‹¬å·æ•°ç»„è®¿é—® *)
  let test_chinese_bracket_array_access () =
    let tokens = [
      (QuotedIdentifierToken "æ•°ç»„", { line = 1; column = 1; filename = "test" });
      (ChineseLeftBracket, { line = 1; column = 3; filename = "test" });
      (IntToken 1, { line = 1; column = 4; filename = "test" });
      (ChineseRightBracket, { line = 1; column = 5; filename = "test" });
      (EOF, { line = 1; column = 6; filename = "test" });
    ] in
    let state = create_test_state tokens in
    let base_expr = VarExpr "æ•°ç»„" in
    let expr, _ = parse_postfix_expr base_expr state in
    check (testable pp_expr equal_expr) "ä¸­æ–‡æ‹¬å·æ•°ç»„è®¿é—®è§£æ"
      (ArrayAccessExpr (VarExpr "æ•°ç»„", LitExpr (IntLit 1))) expr

end

(** å¤åˆè¡¨è¾¾å¼æµ‹è¯• *)
module CompoundExpressionTests = struct

  (** æµ‹è¯•æ‹¬å·è¡¨è¾¾å¼ *)
  let test_parenthesized_expression () =
    let tokens = [
      (LeftParen, { line = 1; column = 1; filename = "test" });
      (IntToken 42, { line = 1; column = 2; filename = "test" });
      (Plus, { line = 1; column = 4; filename = "test" });
      (IntToken 1, { line = 1; column = 6; filename = "test" });
      (RightParen, { line = 1; column = 7; filename = "test" });
      (EOF, { line = 1; column = 8; filename = "test" });
    ] in
    let state = create_test_state tokens in
    let expr, _ = parse_primary_expr state in
    let expected = BinaryOpExpr (LitExpr (IntLit 42), Add, LitExpr (IntLit 1)) in
    check (testable pp_expr equal_expr) "æ‹¬å·è¡¨è¾¾å¼è§£æ" expected expr

  (** æµ‹è¯•ä¸­æ–‡æ‹¬å·è¡¨è¾¾å¼ *)
  let test_chinese_parenthesized_expression () =
    let tokens = [
      (ChineseLeftParen, { line = 1; column = 1; filename = "test" });
      (StringToken "æµ‹è¯•", { line = 1; column = 2; filename = "test" });
      (ChineseRightParen, { line = 1; column = 5; filename = "test" });
      (EOF, { line = 1; column = 6; filename = "test" });
    ] in
    let state = create_test_state tokens in
    let expr, _ = parse_primary_expr state in
    check (testable pp_expr equal_expr) "ä¸­æ–‡æ‹¬å·è¡¨è¾¾å¼è§£æ" (LitExpr (StringLit "æµ‹è¯•")) expr

end

(** Unicode å’Œä¸­æ–‡å­—ç¬¦å¤„ç†æµ‹è¯• *)
module UnicodeTests = struct

  (** æµ‹è¯• Unicode å­—ç¬¦ä¸²å¤„ç† *)
  let test_unicode_strings () =
    let test_cases = [
      ("æ˜¥çœ ä¸è§‰æ™“", "ç»å…¸è¯—å¥");
      ("ğŸŒ¸ğŸŒºğŸŒ»", "è¡¨æƒ…ç¬¦å·");
      ("Î±Î²Î³Î´Îµ", "å¸Œè…Šå­—æ¯");
      ("Ù…Ø±Ø­Ø¨Ø§", "é˜¿æ‹‰ä¼¯æ–‡");
      ("ã“ã‚“ã«ã¡ã¯", "æ—¥æ–‡");
      ("í•œê¸€", "éŸ©æ–‡");
      ("Ã‰mojis cafÃ© naÃ¯ve", "å¸¦é‡éŸ³ç¬¦å·çš„æ‹‰ä¸å­—æ¯");
    ] in
    List.iter (fun (text, desc) ->
      let tokens = [
        (StringToken text, { line = 1; column = 1; filename = "test" });
        (EOF, { line = 1; column = (String.length text + 1); filename = "test" });
      ] in
      let state = create_test_state tokens in
      let expr, _ = parse_primary_expr state in
      check (testable pp_expr equal_expr) desc (LitExpr (StringLit text)) expr
    ) test_cases

  (** æµ‹è¯•ä¸­æ–‡æ ‡è¯†ç¬¦ *)
  let test_chinese_identifiers () =
    let test_cases = [
      ("å˜é‡", "ç®€å•ä¸­æ–‡æ ‡è¯†ç¬¦");
      ("è¯—è¯è§£æå™¨", "å¤æ‚ä¸­æ–‡æ ‡è¯†ç¬¦");
      ("ç”¨æˆ·_è¾“å…¥", "ä¸­è‹±æ··åˆæ ‡è¯†ç¬¦");
      ("æ•°æ®_2024", "å¸¦æ•°å­—çš„ä¸­æ–‡æ ‡è¯†ç¬¦");
    ] in
    List.iter (fun (id, desc) ->
      let tokens = [
        (QuotedIdentifierToken id, { line = 1; column = 1; filename = "test" });
        (EOF, { line = 1; column = (String.length id + 1); filename = "test" });
      ] in
      let state = create_test_state tokens in
      let expr, _ = parse_primary_expr state in
      check (testable pp_expr equal_expr) desc (VarExpr id) expr
    ) test_cases

end

(** é”™è¯¯å¤„ç†å’Œè¾¹ç•Œæ¡ä»¶æµ‹è¯• *)
module ErrorHandlingTests = struct

  (** æµ‹è¯•æ— æ•ˆ token å¤„ç† *)
  let test_invalid_token_handling () =
    (* è¿™ä¸ªæµ‹è¯•æ£€æŸ¥è§£æå™¨å¦‚ä½•å¤„ç†æ— æ•ˆçš„ token åºåˆ— *)
    let tokens = [
      (EOF, { line = 1; column = 1; filename = "test" });
    ] in
    let state = create_test_state tokens in
    try
      let _ = parse_primary_expr state in
      fail "åº”è¯¥æŠ›å‡ºè§£æé”™è¯¯"
    with
    | _ -> () (* é¢„æœŸçš„é”™è¯¯ï¼Œæµ‹è¯•é€šè¿‡ *)

  (** æµ‹è¯•ä¸åŒ¹é…çš„æ‹¬å· *)
  let test_unmatched_parentheses () =
    let tokens = [
      (LeftParen, { line = 1; column = 1; filename = "test" });
      (IntToken 42, { line = 1; column = 2; filename = "test" });
      (* ç¼ºå°‘å³æ‹¬å· *)
      (EOF, { line = 1; column = 4; filename = "test" });
    ] in
    let state = create_test_state tokens in
    try
      let _ = parse_primary_expr state in
      fail "åº”è¯¥æ£€æµ‹åˆ°ä¸åŒ¹é…çš„æ‹¬å·"
    with
    | _ -> () (* é¢„æœŸçš„é”™è¯¯ï¼Œæµ‹è¯•é€šè¿‡ *)

  (** æµ‹è¯•ç©ºè¡¨è¾¾å¼å¤„ç† *)
  let test_empty_expression () =
    let tokens = [
      (EOF, { line = 1; column = 1; filename = "test" });
    ] in
    let state = create_test_state tokens in
    try
      let _ = parse_primary_expr state in
      fail "åº”è¯¥å¤„ç†ç©ºè¡¨è¾¾å¼é”™è¯¯"
    with
    | _ -> () (* é¢„æœŸçš„é”™è¯¯ï¼Œæµ‹è¯•é€šè¿‡ *)

end

(** æ€§èƒ½å’Œå‹åŠ›æµ‹è¯• *)
module PerformanceTests = struct

  (** æµ‹è¯•æ·±åº¦åµŒå¥—è¡¨è¾¾å¼ *)
  let test_deep_nesting () =
    (* åˆ›å»ºæ·±åº¦åµŒå¥—çš„å­—æ®µè®¿é—®è¡¨è¾¾å¼: obj.a.b.c.d.e *)
    let tokens = [
      (QuotedIdentifierToken "obj", { line = 1; column = 1; filename = "test" });
      (Dot, { line = 1; column = 4; filename = "test" });
      (QuotedIdentifierToken "a", { line = 1; column = 5; filename = "test" });
      (Dot, { line = 1; column = 6; filename = "test" });
      (QuotedIdentifierToken "b", { line = 1; column = 7; filename = "test" });
      (Dot, { line = 1; column = 8; filename = "test" });
      (QuotedIdentifierToken "c", { line = 1; column = 9; filename = "test" });
      (Dot, { line = 1; column = 10; filename = "test" });
      (QuotedIdentifierToken "d", { line = 1; column = 11; filename = "test" });
      (Dot, { line = 1; column = 12; filename = "test" });
      (QuotedIdentifierToken "e", { line = 1; column = 13; filename = "test" });
      (EOF, { line = 1; column = 14; filename = "test" });
    ] in
    let state = create_test_state tokens in
    let base_expr = VarExpr "obj" in
    let expr, _ = parse_postfix_expr base_expr state in
    
    (* éªŒè¯åµŒå¥—ç»“æ„æ­£ç¡® *)
    let rec check_nesting expr expected_depth = 
      match expr with
      | FieldAccessExpr (inner, _) -> check_nesting inner (expected_depth - 1)
      | VarExpr "obj" when expected_depth = 0 -> ()
      | _ -> fail "æ·±åº¦åµŒå¥—ç»“æ„è§£æé”™è¯¯"
    in
    check_nesting expr 5

  (** æµ‹è¯•å¤§é‡è¿ç»­æ•°ç»„è®¿é—® *)
  let test_multiple_array_access () =
    (* åˆ›å»º arr[0][1][2] çš„è®¿é—®æ¨¡å¼ *)
    let tokens = [
      (QuotedIdentifierToken "arr", { line = 1; column = 1; filename = "test" });
      (LeftBracket, { line = 1; column = 4; filename = "test" });
      (IntToken 0, { line = 1; column = 5; filename = "test" });
      (RightBracket, { line = 1; column = 6; filename = "test" });
      (LeftBracket, { line = 1; column = 7; filename = "test" });
      (IntToken 1, { line = 1; column = 8; filename = "test" });
      (RightBracket, { line = 1; column = 9; filename = "test" });
      (LeftBracket, { line = 1; column = 10; filename = "test" });
      (IntToken 2, { line = 1; column = 11; filename = "test" });
      (RightBracket, { line = 1; column = 12; filename = "test" });
      (EOF, { line = 1; column = 13; filename = "test" });
    ] in
    let state = create_test_state tokens in
    let base_expr = VarExpr "arr" in
    let expr, _ = parse_postfix_expr base_expr state in
    
    (* éªŒè¯å¤šé‡æ•°ç»„è®¿é—®ç»“æ„ *)
    let expected = ArrayAccessExpr (
      ArrayAccessExpr (
        ArrayAccessExpr (VarExpr "arr", LitExpr (IntLit 0)),
        LitExpr (IntLit 1)
      ),
      LitExpr (IntLit 2)
    ) in
    check (testable pp_expr equal_expr) "å¤šé‡æ•°ç»„è®¿é—®è§£æ" expected expr

end

(** æµ‹è¯•å¥—ä»¶æ³¨å†Œ *)
let test_suite = [
  "åŸºç¡€è¡¨è¾¾å¼è§£æ", [
    test_case "æ•´æ•°å­—é¢é‡" `Quick BasicExpressionTests.test_integer_literal;
    test_case "æµ®ç‚¹æ•°å­—é¢é‡" `Quick BasicExpressionTests.test_float_literal;
    test_case "å­—ç¬¦ä¸²å­—é¢é‡" `Quick BasicExpressionTests.test_string_literal;
    test_case "å¸ƒå°”å­—é¢é‡" `Quick BasicExpressionTests.test_boolean_literals;
    test_case "æ ‡è¯†ç¬¦è§£æ" `Quick BasicExpressionTests.test_identifier_parsing;
  ];
  
  "åç¼€è¡¨è¾¾å¼", [
    test_case "å­—æ®µè®¿é—®" `Quick PostfixExpressionTests.test_field_access;
    test_case "å¤šçº§å­—æ®µè®¿é—®" `Quick PostfixExpressionTests.test_nested_field_access;
    test_case "æ•°ç»„è®¿é—®" `Quick PostfixExpressionTests.test_array_access;
    test_case "ä¸­æ–‡æ‹¬å·æ•°ç»„è®¿é—®" `Quick PostfixExpressionTests.test_chinese_bracket_array_access;
  ];
  
  "å¤åˆè¡¨è¾¾å¼", [
    test_case "æ‹¬å·è¡¨è¾¾å¼" `Quick CompoundExpressionTests.test_parenthesized_expression;
    test_case "ä¸­æ–‡æ‹¬å·è¡¨è¾¾å¼" `Quick CompoundExpressionTests.test_chinese_parenthesized_expression;
  ];
  
  "Unicodeå­—ç¬¦å¤„ç†", [
    test_case "Unicodeå­—ç¬¦ä¸²" `Quick UnicodeTests.test_unicode_strings;
    test_case "ä¸­æ–‡æ ‡è¯†ç¬¦" `Quick UnicodeTests.test_chinese_identifiers;
  ];
  
  "é”™è¯¯å¤„ç†", [
    test_case "æ— æ•ˆtokenå¤„ç†" `Quick ErrorHandlingTests.test_invalid_token_handling;
    test_case "ä¸åŒ¹é…æ‹¬å·" `Quick ErrorHandlingTests.test_unmatched_parentheses;
    test_case "ç©ºè¡¨è¾¾å¼å¤„ç†" `Quick ErrorHandlingTests.test_empty_expression;
  ];
  
  "æ€§èƒ½æµ‹è¯•", [
    test_case "æ·±åº¦åµŒå¥—" `Quick PerformanceTests.test_deep_nesting;
    test_case "å¤šé‡æ•°ç»„è®¿é—®" `Quick PerformanceTests.test_multiple_array_access;
  ];
]

(** è¿è¡Œæ‰€æœ‰æµ‹è¯• *)
let () = 
  Printf.printf "éª†è¨€è§£æå™¨åŸºç¡€è¡¨è¾¾å¼æ¨¡å—å¢å¼ºæµ‹è¯• - Phase 25\n";
  Printf.printf "======================================================\n";
  run "Parser Primary Expressions Enhanced Tests" test_suite