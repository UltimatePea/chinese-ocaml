(** éª†è¨€è¯æ³•ä»¤ç‰Œæ¨¡å—ç»¼åˆæµ‹è¯•å¥—ä»¶ - Fix #1009 Phase 2 æ ¸å¿ƒæ¨¡å—æµ‹è¯•è¦†ç›–ç‡æå‡ *)

open Alcotest
open Yyocamlc_lib.Lexer_tokens

(** æµ‹è¯•è¾…åŠ©å·¥å…·æ¨¡å— *)
module TestHelpers = struct
  (** åˆ›å»ºä½ç½®ä¿¡æ¯ *)
  let make_pos line column filename = { line; column; filename }

  (** åˆ›å»ºå¸¦ä½ç½®çš„token *)
  let make_positioned_token token line column filename =
    (token, make_pos line column filename)

  (** æ¯”è¾ƒä¸¤ä¸ªtokenæ˜¯å¦ç›¸ç­‰ *)
  let tokens_equal t1 t2 = equal_token t1 t2

  (** æ¯”è¾ƒä½ç½®ä¿¡æ¯æ˜¯å¦ç›¸ç­‰ *)
  let positions_equal p1 p2 = equal_position p1 p2

  (** æ¯”è¾ƒå¸¦ä½ç½®tokenæ˜¯å¦ç›¸ç­‰ *)
  let positioned_tokens_equal pt1 pt2 = equal_positioned_token pt1 pt2
end

(** 1. åŸºæœ¬å­—é¢é‡tokenæµ‹è¯• *)

let test_literal_tokens () =
  (* æ•´æ•°token *)
  let int_token = IntToken 42 in
  check bool "æ•´æ•°tokenåˆ›å»º" true (TestHelpers.tokens_equal int_token (IntToken 42));
  check bool "ä¸åŒæ•´æ•°token" false (TestHelpers.tokens_equal int_token (IntToken 24));
  
  (* æµ®ç‚¹æ•°token *)
  let float_token = FloatToken 3.14 in
  check bool "æµ®ç‚¹æ•°tokenåˆ›å»º" true (TestHelpers.tokens_equal float_token (FloatToken 3.14));
  
  (* ä¸­æ–‡æ•°å­—token *)
  let chinese_token = ChineseNumberToken "äº”" in
  check bool "ä¸­æ–‡æ•°å­—tokenåˆ›å»º" true (TestHelpers.tokens_equal chinese_token (ChineseNumberToken "äº”"));
  
  (* å­—ç¬¦ä¸²token *)
  let string_token = StringToken "hello" in
  check bool "å­—ç¬¦ä¸²tokenåˆ›å»º" true (TestHelpers.tokens_equal string_token (StringToken "hello"));
  
  (* å¸ƒå°”token *)
  let bool_token = BoolToken true in
  check bool "å¸ƒå°”tokenåˆ›å»º" true (TestHelpers.tokens_equal bool_token (BoolToken true));
  check bool "ä¸åŒå¸ƒå°”å€¼" false (TestHelpers.tokens_equal bool_token (BoolToken false))

let test_identifier_tokens () =
  (* å¼•ç”¨æ ‡è¯†ç¬¦token *)
  let quoted_id = QuotedIdentifierToken "å˜é‡å" in
  check bool "å¼•ç”¨æ ‡è¯†ç¬¦token" true (TestHelpers.tokens_equal quoted_id (QuotedIdentifierToken "å˜é‡å"));
  
  (* ç‰¹æ®Šæ ‡è¯†ç¬¦token *)
  let special_id = IdentifierTokenSpecial "æ•°å€¼" in
  check bool "ç‰¹æ®Šæ ‡è¯†ç¬¦token" true (TestHelpers.tokens_equal special_id (IdentifierTokenSpecial "æ•°å€¼"));
  
  (* ä¸åŒæ ‡è¯†ç¬¦ä¸ç›¸ç­‰ *)
  check bool "ä¸åŒå¼•ç”¨æ ‡è¯†ç¬¦" false (TestHelpers.tokens_equal quoted_id (QuotedIdentifierToken "å…¶ä»–åç§°"))

(** 2. åŸºç¡€å…³é”®å­—tokenæµ‹è¯• *)

let test_basic_keywords () =
  (* åŸºç¡€è¯­è¨€å…³é”®å­— *)
  let keywords = [
    (LetKeyword, "Letå…³é”®å­—");
    (RecKeyword, "Recå…³é”®å­—");
    (InKeyword, "Inå…³é”®å­—");
    (FunKeyword, "Funå…³é”®å­—");
    (IfKeyword, "Ifå…³é”®å­—");
    (ThenKeyword, "Thenå…³é”®å­—");
    (ElseKeyword, "Elseå…³é”®å­—");
    (MatchKeyword, "Matchå…³é”®å­—");
    (WithKeyword, "Withå…³é”®å­—");
    (TypeKeyword, "Typeå…³é”®å­—");
    (TrueKeyword, "Trueå…³é”®å­—");
    (FalseKeyword, "Falseå…³é”®å­—");
    (AndKeyword, "Andå…³é”®å­—");
    (OrKeyword, "Orå…³é”®å­—");
    (NotKeyword, "Notå…³é”®å­—");
  ] in
  
  List.iter (fun (token, desc) ->
    check bool desc true (TestHelpers.tokens_equal token token)
  ) keywords;
  
  (* æµ‹è¯•å…³é”®å­—ä¸ç›¸ç­‰ *)
  check bool "ä¸åŒå…³é”®å­—ä¸ç›¸ç­‰" false (TestHelpers.tokens_equal LetKeyword FunKeyword)

let test_semantic_keywords () =
  (* è¯­ä¹‰ç±»å‹ç³»ç»Ÿå…³é”®å­— *)
  let semantic_keywords = [
    (AsKeyword, "Aså…³é”®å­—");
    (CombineKeyword, "Combineå…³é”®å­—");
    (WithOpKeyword, "WithOpå…³é”®å­—");
    (WhenKeyword, "Whenå…³é”®å­—");
  ] in
  
  List.iter (fun (token, desc) ->
    check bool desc true (TestHelpers.tokens_equal token token)
  ) semantic_keywords

let test_exception_keywords () =
  (* å¼‚å¸¸å¤„ç†å…³é”®å­— *)
  let exception_keywords = [
    (ExceptionKeyword, "Exceptionå…³é”®å­—");
    (RaiseKeyword, "Raiseå…³é”®å­—");
    (TryKeyword, "Tryå…³é”®å­—");
    (CatchKeyword, "Catchå…³é”®å­—");
    (FinallyKeyword, "Finallyå…³é”®å­—");
  ] in
  
  List.iter (fun (token, desc) ->
    check bool desc true (TestHelpers.tokens_equal token token)
  ) exception_keywords

(** 3. æ¨¡å—ç³»ç»Ÿå…³é”®å­—æµ‹è¯• *)

let test_module_keywords () =
  let module_keywords = [
    (ModuleKeyword, "Moduleå…³é”®å­—");
    (ModuleTypeKeyword, "ModuleTypeå…³é”®å­—");
    (SigKeyword, "Sigå…³é”®å­—");
    (EndKeyword, "Endå…³é”®å­—");
    (FunctorKeyword, "Functorå…³é”®å­—");
    (IncludeKeyword, "Includeå…³é”®å­—");
  ] in
  
  List.iter (fun (token, desc) ->
    check bool desc true (TestHelpers.tokens_equal token token)
  ) module_keywords

(** 4. æ–‡è¨€æ–‡é£æ ¼å…³é”®å­—æµ‹è¯• *)

let test_wenyan_keywords () =
  let wenyan_keywords = [
    (HaveKeyword, "Haveå…³é”®å­—ï¼ˆå¾æœ‰ï¼‰");
    (OneKeyword, "Oneå…³é”®å­—ï¼ˆä¸€ï¼‰");
    (NameKeyword, "Nameå…³é”®å­—ï¼ˆåæ›°ï¼‰");
    (SetKeyword, "Setå…³é”®å­—ï¼ˆè®¾ï¼‰");
    (AlsoKeyword, "Alsoå…³é”®å­—ï¼ˆä¹Ÿï¼‰");
    (ThenGetKeyword, "ThenGetå…³é”®å­—ï¼ˆä¹ƒï¼‰");
    (CallKeyword, "Callå…³é”®å­—ï¼ˆæ›°ï¼‰");
    (ValueKeyword, "Valueå…³é”®å­—ï¼ˆå…¶å€¼ï¼‰");
    (AsForKeyword, "AsForå…³é”®å­—ï¼ˆä¸ºï¼‰");
    (NumberKeyword, "Numberå…³é”®å­—ï¼ˆæ•°ï¼‰");
  ] in
  
  List.iter (fun (token, desc) ->
    check bool desc true (TestHelpers.tokens_equal token token)
  ) wenyan_keywords

let test_wenyan_extended_keywords () =
  let extended_keywords = [
    (WantExecuteKeyword, "WantExecuteå…³é”®å­—ï¼ˆæ¬²è¡Œï¼‰");
    (MustFirstGetKeyword, "MustFirstGetå…³é”®å­—ï¼ˆå¿…å…ˆå¾—ï¼‰");
    (ForThisKeyword, "ForThiså…³é”®å­—ï¼ˆç‚ºæ˜¯ï¼‰");
    (TimesKeyword, "Timeså…³é”®å­—ï¼ˆéï¼‰");
    (EndCloudKeyword, "EndCloudå…³é”®å­—ï¼ˆäº‘äº‘ï¼‰");
    (IfWenyanKeyword, "IfWenyanå…³é”®å­—ï¼ˆè‹¥ï¼‰");
    (ThenWenyanKeyword, "ThenWenyanå…³é”®å­—ï¼ˆè€…ï¼‰");
    (GreaterThanWenyan, "GreaterThanWenyanï¼ˆå¤§äºï¼‰");
    (LessThanWenyan, "LessThanWenyanï¼ˆå°äºï¼‰");
  ] in
  
  List.iter (fun (token, desc) ->
    check bool desc true (TestHelpers.tokens_equal token token)
  ) extended_keywords

(** 5. å¤é›…ä½“å…³é”®å­—æµ‹è¯• *)

let test_ancient_keywords () =
  let ancient_keywords = [
    (AncientDefineKeyword, "AncientDefineå…³é”®å­—ï¼ˆå¤«...è€…ï¼‰");
    (AncientEndKeyword, "AncientEndå…³é”®å­—ï¼ˆä¹Ÿï¼‰");
    (AncientAlgorithmKeyword, "AncientAlgorithmå…³é”®å­—ï¼ˆç®—æ³•ï¼‰");
    (AncientCompleteKeyword, "AncientCompleteå…³é”®å­—ï¼ˆç«Ÿï¼‰");
    (AncientObserveKeyword, "AncientObserveå…³é”®å­—ï¼ˆè§‚ï¼‰");
    (AncientNatureKeyword, "AncientNatureå…³é”®å­—ï¼ˆæ€§ï¼‰");
    (AncientIfKeyword, "AncientIfå…³é”®å­—ï¼ˆè‹¥ï¼‰");
    (AncientThenKeyword, "AncientThenå…³é”®å­—ï¼ˆåˆ™ï¼‰");
    (AncientOtherwiseKeyword, "AncientOtherwiseå…³é”®å­—ï¼ˆä½™è€…ï¼‰");
    (AncientAnswerKeyword, "AncientAnswerå…³é”®å­—ï¼ˆç­”ï¼‰");
  ] in
  
  List.iter (fun (token, desc) ->
    check bool desc true (TestHelpers.tokens_equal token token)
  ) ancient_keywords

let test_ancient_particles () =
  let ancient_particles = [
    (AncientParticleOf, "AncientParticleOfï¼ˆä¹‹ï¼‰");
    (AncientParticleFun, "AncientParticleFunï¼ˆç„‰ï¼‰");
    (AncientParticleThe, "AncientParticleTheï¼ˆå…¶ï¼‰");
    (AncientCallItKeyword, "AncientCallItå…³é”®å­—ï¼ˆåæ›°ï¼‰");
  ] in
  
  List.iter (fun (token, desc) ->
    check bool desc true (TestHelpers.tokens_equal token token)
  ) ancient_particles

let test_ancient_record_keywords () =
  let ancient_record_keywords = [
    (AncientRecordStartKeyword, "AncientRecordStartå…³é”®å­—ï¼ˆæ®å¼€å§‹ï¼‰");
    (AncientRecordEndKeyword, "AncientRecordEndå…³é”®å­—ï¼ˆæ®ç»“æŸï¼‰");
    (AncientRecordEmptyKeyword, "AncientRecordEmptyå…³é”®å­—ï¼ˆæ®ç©ºï¼‰");
    (AncientRecordUpdateKeyword, "AncientRecordUpdateå…³é”®å­—ï¼ˆæ®æ›´æ–°ï¼‰");
    (AncientRecordFinishKeyword, "AncientRecordFinishå…³é”®å­—ï¼ˆæ®æ¯•ï¼‰");
  ] in
  
  List.iter (fun (token, desc) ->
    check bool desc true (TestHelpers.tokens_equal token token)
  ) ancient_record_keywords

(** 6. è‡ªç„¶è¯­è¨€å‡½æ•°å®šä¹‰å…³é”®å­—æµ‹è¯• *)

let test_natural_language_keywords () =
  let natural_keywords = [
    (DefineKeyword, "Defineå…³é”®å­—ï¼ˆå®šä¹‰ï¼‰");
    (AcceptKeyword, "Acceptå…³é”®å­—ï¼ˆæ¥å—ï¼‰");
    (ReturnWhenKeyword, "ReturnWhenå…³é”®å­—ï¼ˆæ—¶è¿”å›ï¼‰");
    (ElseReturnKeyword, "ElseReturnå…³é”®å­—ï¼ˆå¦åˆ™è¿”å›ï¼‰");
    (MultiplyKeyword, "Multiplyå…³é”®å­—ï¼ˆä¹˜ä»¥ï¼‰");
    (DivideKeyword, "Divideå…³é”®å­—ï¼ˆé™¤ä»¥ï¼‰");
    (AddToKeyword, "AddToå…³é”®å­—ï¼ˆåŠ ä¸Šï¼‰");
    (SubtractKeyword, "Subtractå…³é”®å­—ï¼ˆå‡å»ï¼‰");
    (IsKeyword, "Iså…³é”®å­—ï¼ˆä¸ºï¼‰");
    (EqualToKeyword, "EqualToå…³é”®å­—ï¼ˆç­‰äºï¼‰");
  ] in
  
  List.iter (fun (token, desc) ->
    check bool desc true (TestHelpers.tokens_equal token token)
  ) natural_keywords

let test_natural_language_extended () =
  let extended_natural = [
    (LessThanEqualToKeyword, "LessThanEqualToå…³é”®å­—ï¼ˆå°äºç­‰äºï¼‰");
    (FirstElementKeyword, "FirstElementå…³é”®å­—ï¼ˆé¦–å…ƒç´ ï¼‰");
    (RemainingKeyword, "Remainingå…³é”®å­—ï¼ˆå‰©ä½™ï¼‰");
    (EmptyKeyword, "Emptyå…³é”®å­—ï¼ˆç©ºï¼‰");
    (CharacterCountKeyword, "CharacterCountå…³é”®å­—ï¼ˆå­—ç¬¦æ•°é‡ï¼‰");
    (InputKeyword, "Inputå…³é”®å­—ï¼ˆè¾“å…¥ï¼‰");
    (OutputKeyword, "Outputå…³é”®å­—ï¼ˆè¾“å‡ºï¼‰");
    (MinusOneKeyword, "MinusOneå…³é”®å­—ï¼ˆå‡ä¸€ï¼‰");
    (PlusKeyword, "Pluså…³é”®å­—ï¼ˆåŠ ï¼‰");
    (SmallKeyword, "Smallå…³é”®å­—ï¼ˆå°ï¼‰");
    (ShouldGetKeyword, "ShouldGetå…³é”®å­—ï¼ˆåº”å¾—ï¼‰");
  ] in
  
  List.iter (fun (token, desc) ->
    check bool desc true (TestHelpers.tokens_equal token token)
  ) extended_natural

(** 7. ç±»å‹å…³é”®å­—æµ‹è¯• *)

let test_type_keywords () =
  let type_keywords = [
    (IntTypeKeyword, "IntTypeå…³é”®å­—ï¼ˆæ•´æ•°ï¼‰");
    (FloatTypeKeyword, "FloatTypeå…³é”®å­—ï¼ˆæµ®ç‚¹æ•°ï¼‰");
    (StringTypeKeyword, "StringTypeå…³é”®å­—ï¼ˆå­—ç¬¦ä¸²ï¼‰");
    (BoolTypeKeyword, "BoolTypeå…³é”®å­—ï¼ˆå¸ƒå°”ï¼‰");
    (UnitTypeKeyword, "UnitTypeå…³é”®å­—ï¼ˆå•å…ƒï¼‰");
    (ListTypeKeyword, "ListTypeå…³é”®å­—ï¼ˆåˆ—è¡¨ï¼‰");
    (ArrayTypeKeyword, "ArrayTypeå…³é”®å­—ï¼ˆæ•°ç»„ï¼‰");
    (VariantKeyword, "Variantå…³é”®å­—ï¼ˆå˜ä½“ï¼‰");
    (TagKeyword, "Tagå…³é”®å­—ï¼ˆæ ‡ç­¾ï¼‰");
  ] in
  
  List.iter (fun (token, desc) ->
    check bool desc true (TestHelpers.tokens_equal token token)
  ) type_keywords

(** 8. å¤å…¸è¯—è¯ç›¸å…³å…³é”®å­—æµ‹è¯• *)

let test_poetry_keywords () =
  let poetry_keywords = [
    (RhymeKeyword, "Rhymeå…³é”®å­—ï¼ˆéŸµï¼‰");
    (ToneKeyword, "Toneå…³é”®å­—ï¼ˆè°ƒï¼‰");
    (ToneLevelKeyword, "ToneLevelå…³é”®å­—ï¼ˆå¹³ï¼‰");
    (ToneFallingKeyword, "ToneFallingå…³é”®å­—ï¼ˆä»„ï¼‰");
    (ToneRisingKeyword, "ToneRisingå…³é”®å­—ï¼ˆä¸Šï¼‰");
    (ToneDepartingKeyword, "ToneDepartingå…³é”®å­—ï¼ˆå»ï¼‰");
    (ToneEnteringKeyword, "ToneEnteringå…³é”®å­—ï¼ˆå…¥ï¼‰");
    (ParallelKeyword, "Parallelå…³é”®å­—ï¼ˆå¯¹ï¼‰");
    (PairedKeyword, "Pairedå…³é”®å­—ï¼ˆå¶ï¼‰");
    (AntitheticKeyword, "Antitheticå…³é”®å­—ï¼ˆåï¼‰");
    (BalancedKeyword, "Balancedå…³é”®å­—ï¼ˆè¡¡ï¼‰");
  ] in
  
  List.iter (fun (token, desc) ->
    check bool desc true (TestHelpers.tokens_equal token token)
  ) poetry_keywords

let test_poetry_forms () =
  let poetry_forms = [
    (PoetryKeyword, "Poetryå…³é”®å­—ï¼ˆè¯—ï¼‰");
    (FourCharKeyword, "FourCharå…³é”®å­—ï¼ˆå››è¨€ï¼‰");
    (FiveCharKeyword, "FiveCharå…³é”®å­—ï¼ˆäº”è¨€ï¼‰");
    (SevenCharKeyword, "SevenCharå…³é”®å­—ï¼ˆä¸ƒè¨€ï¼‰");
    (ParallelStructKeyword, "ParallelStructå…³é”®å­—ï¼ˆéªˆä½“ï¼‰");
    (RegulatedVerseKeyword, "RegulatedVerseå…³é”®å­—ï¼ˆå¾‹è¯—ï¼‰");
    (QuatrainKeyword, "Quatrainå…³é”®å­—ï¼ˆç»å¥ï¼‰");
    (CoupletKeyword, "Coupletå…³é”®å­—ï¼ˆå¯¹è”ï¼‰");
    (AntithesisKeyword, "Antithesiså…³é”®å­—ï¼ˆå¯¹ä»—ï¼‰");
    (MeterKeyword, "Meterå…³é”®å­—ï¼ˆéŸµå¾‹ï¼‰");
    (CadenceKeyword, "Cadenceå…³é”®å­—ï¼ˆéŸ³å¾‹ï¼‰");
  ] in
  
  List.iter (fun (token, desc) ->
    check bool desc true (TestHelpers.tokens_equal token token)
  ) poetry_forms

(** 9. è¿ç®—ç¬¦tokenæµ‹è¯• *)

let test_arithmetic_operators () =
  let arithmetic_ops = [
    (Plus, "Plusè¿ç®—ç¬¦ï¼ˆ+ï¼‰");
    (Minus, "Minusè¿ç®—ç¬¦ï¼ˆ-ï¼‰");
    (Multiply, "Multiplyè¿ç®—ç¬¦ï¼ˆ*ï¼‰");
    (Star, "Starè¿ç®—ç¬¦ï¼ˆ*åˆ«åï¼‰");
    (Divide, "Divideè¿ç®—ç¬¦ï¼ˆ/ï¼‰");
    (Slash, "Slashè¿ç®—ç¬¦ï¼ˆ/åˆ«åï¼‰");
    (Modulo, "Moduloè¿ç®—ç¬¦ï¼ˆ%ï¼‰");
    (Concat, "Concatè¿ç®—ç¬¦ï¼ˆ^ï¼‰");
  ] in
  
  List.iter (fun (token, desc) ->
    check bool desc true (TestHelpers.tokens_equal token token)
  ) arithmetic_ops;
  
  (* æµ‹è¯•åˆ«åtokens *)
  check bool "Starå’ŒMultiplyæ˜¯ä¸åŒtoken" false (TestHelpers.tokens_equal Star Multiply);
  check bool "Slashå’ŒDivideæ˜¯ä¸åŒtoken" false (TestHelpers.tokens_equal Slash Divide)

let test_comparison_operators () =
  let comparison_ops = [
    (Assign, "Assignè¿ç®—ç¬¦ï¼ˆ=ï¼‰");
    (Equal, "Equalè¿ç®—ç¬¦ï¼ˆ==ï¼‰");
    (NotEqual, "NotEqualè¿ç®—ç¬¦ï¼ˆ<>ï¼‰");
    (Less, "Lessè¿ç®—ç¬¦ï¼ˆ<ï¼‰");
    (LessEqual, "LessEqualè¿ç®—ç¬¦ï¼ˆ<=ï¼‰");
    (Greater, "Greaterè¿ç®—ç¬¦ï¼ˆ>ï¼‰");
    (GreaterEqual, "GreaterEqualè¿ç®—ç¬¦ï¼ˆ>=ï¼‰");
  ] in
  
  List.iter (fun (token, desc) ->
    check bool desc true (TestHelpers.tokens_equal token token)
  ) comparison_ops

let test_special_operators () =
  let special_ops = [
    (Arrow, "Arrowè¿ç®—ç¬¦ï¼ˆ->ï¼‰");
    (DoubleArrow, "DoubleArrowè¿ç®—ç¬¦ï¼ˆ=>ï¼‰");
    (Dot, "Dotè¿ç®—ç¬¦ï¼ˆ.ï¼‰");
    (DoubleDot, "DoubleDotè¿ç®—ç¬¦ï¼ˆ..ï¼‰");
    (TripleDot, "TripleDotè¿ç®—ç¬¦ï¼ˆ...ï¼‰");
    (Bang, "Bangè¿ç®—ç¬¦ï¼ˆ!ï¼‰");
    (RefAssign, "RefAssignè¿ç®—ç¬¦ï¼ˆ:=ï¼‰");
    (AssignArrow, "AssignArrowè¿ç®—ç¬¦ï¼ˆ<-ï¼‰");
  ] in
  
  List.iter (fun (token, desc) ->
    check bool desc true (TestHelpers.tokens_equal token token)
  ) special_ops

(** 10. åˆ†éš”ç¬¦tokenæµ‹è¯• *)

let test_ascii_separators () =
  let separators = [
    (LeftParen, "LeftParenï¼ˆ(ï¼‰");
    (RightParen, "RightParenï¼ˆ)ï¼‰");
    (LeftBracket, "LeftBracketï¼ˆ[ï¼‰");
    (RightBracket, "RightBracketï¼ˆ]ï¼‰");
    (LeftBrace, "LeftBraceï¼ˆ{ï¼‰");
    (RightBrace, "RightBraceï¼ˆ}ï¼‰");
    (Comma, "Commaï¼ˆ,ï¼‰");
    (Semicolon, "Semicolonï¼ˆ;ï¼‰");
    (Colon, "Colonï¼ˆ:ï¼‰");
    (QuestionMark, "QuestionMarkï¼ˆ?ï¼‰");
    (Tilde, "Tildeï¼ˆ~ï¼‰");
    (Pipe, "Pipeï¼ˆ|ï¼‰");
    (Underscore, "Underscoreï¼ˆ_ï¼‰");
  ] in
  
  List.iter (fun (token, desc) ->
    check bool desc true (TestHelpers.tokens_equal token token)
  ) separators

let test_array_separators () =
  let array_separators = [
    (LeftArray, "LeftArrayï¼ˆ[|ï¼‰");
    (RightArray, "RightArrayï¼ˆ|]ï¼‰");
    (ChineseLeftArray, "ChineseLeftArrayï¼ˆã€Œ|ï¼‰");
    (ChineseRightArray, "ChineseRightArrayï¼ˆ|ã€ï¼‰");
  ] in
  
  List.iter (fun (token, desc) ->
    check bool desc true (TestHelpers.tokens_equal token token)
  ) array_separators

(** 11. ä¸­æ–‡æ ‡ç‚¹ç¬¦å·tokenæµ‹è¯• *)

let test_chinese_punctuation () =
  let chinese_punct = [
    (ChineseLeftParen, "ChineseLeftParenï¼ˆï¼ˆï¼‰");
    (ChineseRightParen, "ChineseRightParenï¼ˆï¼‰ï¼‰");
    (ChineseLeftBracket, "ChineseLeftBracketï¼ˆã€Œï¼‰");
    (ChineseRightBracket, "ChineseRightBracketï¼ˆã€ï¼‰");
    (ChineseSquareLeftBracket, "ChineseSquareLeftBracketï¼ˆã€ï¼‰");
    (ChineseSquareRightBracket, "ChineseSquareRightBracketï¼ˆã€‘ï¼‰");
    (ChineseComma, "ChineseCommaï¼ˆï¼Œï¼‰");
    (ChineseSemicolon, "ChineseSemicolonï¼ˆï¼›ï¼‰");
    (ChineseColon, "ChineseColonï¼ˆï¼šï¼‰");
    (ChineseDoubleColon, "ChineseDoubleColonï¼ˆï¼šï¼šï¼‰");
    (ChinesePipe, "ChinesePipeï¼ˆï½œï¼‰");
  ] in
  
  List.iter (fun (token, desc) ->
    check bool desc true (TestHelpers.tokens_equal token token)
  ) chinese_punct

let test_chinese_arrows () =
  let chinese_arrows = [
    (ChineseArrow, "ChineseArrowï¼ˆâ†’ï¼‰");
    (ChineseDoubleArrow, "ChineseDoubleArrowï¼ˆâ‡’ï¼‰");
    (ChineseAssignArrow, "ChineseAssignArrowï¼ˆâ†ï¼‰");
  ] in
  
  List.iter (fun (token, desc) ->
    check bool desc true (TestHelpers.tokens_equal token token)
  ) chinese_arrows;
  
  (* æµ‹è¯•ä¸­æ–‡å’ŒASCIIç‰ˆæœ¬ä¸ç›¸ç­‰ *)
  check bool "ä¸­æ–‡ç®­å¤´ä¸ASCIIç®­å¤´ä¸ç›¸ç­‰" false (TestHelpers.tokens_equal ChineseArrow Arrow);
  check bool "ä¸­æ–‡åŒç®­å¤´ä¸ASCIIåŒç®­å¤´ä¸ç›¸ç­‰" false (TestHelpers.tokens_equal ChineseDoubleArrow DoubleArrow)

(** 12. ç‰¹æ®Štokenæµ‹è¯• *)

let test_special_tokens () =
  (* ç‰¹æ®Štokens *)
  check bool "Newline token" true (TestHelpers.tokens_equal Newline Newline);
  check bool "EOF token" true (TestHelpers.tokens_equal EOF EOF);
  
  (* ç‰¹æ®Štokensä¸ç›¸ç­‰ *)
  check bool "Newlineä¸EOFä¸ç›¸ç­‰" false (TestHelpers.tokens_equal Newline EOF)

(** 13. ä½ç½®ä¿¡æ¯æµ‹è¯• *)

let test_position_creation () =
  let pos = TestHelpers.make_pos 10 5 "test.ly" in
  check int "ä½ç½®è¡Œå·" 10 pos.line;
  check int "ä½ç½®åˆ—å·" 5 pos.column;
  check string "æ–‡ä»¶å" "test.ly" pos.filename

let test_position_equality () =
  let pos1 = TestHelpers.make_pos 1 1 "file1.ly" in
  let pos2 = TestHelpers.make_pos 1 1 "file1.ly" in
  let pos3 = TestHelpers.make_pos 2 1 "file1.ly" in
  let pos4 = TestHelpers.make_pos 1 1 "file2.ly" in
  
  check bool "ç›¸åŒä½ç½®ç›¸ç­‰" true (TestHelpers.positions_equal pos1 pos2);
  check bool "ä¸åŒè¡Œä¸ç›¸ç­‰" false (TestHelpers.positions_equal pos1 pos3);
  check bool "ä¸åŒæ–‡ä»¶ä¸ç›¸ç­‰" false (TestHelpers.positions_equal pos1 pos4)

(** 14. å¸¦ä½ç½®tokenæµ‹è¯• *)

let test_positioned_token_creation () =
  let token = IntToken 42 in
  let pos = TestHelpers.make_pos 5 10 "example.ly" in
  let positioned = TestHelpers.make_positioned_token token 5 10 "example.ly" in
  
  let (actual_token, actual_pos) = positioned in
  check bool "positioned tokenä¸­çš„token" true (TestHelpers.tokens_equal actual_token token);
  check bool "positioned tokenä¸­çš„ä½ç½®" true (TestHelpers.positions_equal actual_pos pos)

let test_positioned_token_equality () =
  let pt1 = TestHelpers.make_positioned_token (IntToken 42) 1 1 "test.ly" in
  let pt2 = TestHelpers.make_positioned_token (IntToken 42) 1 1 "test.ly" in
  let pt3 = TestHelpers.make_positioned_token (IntToken 24) 1 1 "test.ly" in
  let pt4 = TestHelpers.make_positioned_token (IntToken 42) 2 1 "test.ly" in
  
  check bool "ç›¸åŒpositioned tokenç›¸ç­‰" true (TestHelpers.positioned_tokens_equal pt1 pt2);
  check bool "ä¸åŒtokenä¸ç›¸ç­‰" false (TestHelpers.positioned_tokens_equal pt1 pt3);
  check bool "ä¸åŒä½ç½®ä¸ç›¸ç­‰" false (TestHelpers.positioned_tokens_equal pt1 pt4)

(** 15. è¯æ³•é”™è¯¯æµ‹è¯• *)

let test_lex_error () =
  let pos = TestHelpers.make_pos 3 7 "error.ly" in
  let error = LexError ("æ— æ•ˆå­—ç¬¦", pos) in
  
  (* æµ‹è¯•å¼‚å¸¸æŠ›å‡ºå’Œæ•è· *)
  try
    (raise error : unit);
    fail "åº”è¯¥æŠ›å‡ºå¼‚å¸¸"
  with LexError (msg, error_pos) ->
    check string "é”™è¯¯æ¶ˆæ¯" "æ— æ•ˆå­—ç¬¦" msg;
    check bool "é”™è¯¯ä½ç½®" true (TestHelpers.positions_equal error_pos pos)

(** 16. Tokenæ˜¾ç¤ºåŠŸèƒ½æµ‹è¯• *)

let test_token_show () =
  (* æµ‹è¯•showå‡½æ•°ä¸ä¼šå´©æºƒ *)
  let tokens_to_show = [
    IntToken 42;
    StringToken "test";
    QuotedIdentifierToken "å˜é‡";
    LetKeyword;
    Plus;
    LeftParen;
    ChineseLeftParen;
    EOF;
  ] in
  
  List.iter (fun token ->
    let shown = show_token token in
    check bool "show_tokenè¿”å›éç©ºå­—ç¬¦ä¸²" true (String.length shown > 0)
  ) tokens_to_show

let test_position_show () =
  let pos = TestHelpers.make_pos 1 1 "test.ly" in
  let shown = show_position pos in
  check bool "show_positionè¿”å›éç©ºå­—ç¬¦ä¸²" true (String.length shown > 0)

let test_positioned_token_show () =
  let pt = TestHelpers.make_positioned_token (IntToken 42) 1 1 "test.ly" in
  let shown = show_positioned_token pt in
  check bool "show_positioned_tokenè¿”å›éç©ºå­—ç¬¦ä¸²" true (String.length shown > 0)

(** 17. è¾¹ç•Œæ¡ä»¶å’Œå‹åŠ›æµ‹è¯• *)

let test_boundary_conditions () =
  (* æµ‹è¯•æå€¼ *)
  let max_int_token = IntToken max_int in
  let min_int_token = IntToken min_int in
  check bool "æœ€å¤§æ•´æ•°token" true (TestHelpers.tokens_equal max_int_token (IntToken max_int));
  check bool "æœ€å°æ•´æ•°token" true (TestHelpers.tokens_equal min_int_token (IntToken min_int));
  
  (* æµ‹è¯•æé•¿å­—ç¬¦ä¸² *)
  let long_string = String.make 10000 'a' in
  let long_string_token = StringToken long_string in
  check bool "é•¿å­—ç¬¦ä¸²token" true (TestHelpers.tokens_equal long_string_token (StringToken long_string));
  
  (* æµ‹è¯•ç©ºå­—ç¬¦ä¸² *)
  let empty_string_token = StringToken "" in
  check bool "ç©ºå­—ç¬¦ä¸²token" true (TestHelpers.tokens_equal empty_string_token (StringToken ""))

let test_unicode_handling () =
  (* æµ‹è¯•Unicodeå­—ç¬¦ä¸² *)
  let unicode_strings = [
    "ä½ å¥½ä¸–ç•Œ";
    "ğŸŒŸğŸ¨ğŸ”¥";
    "Î±Î²Î³Î´Îµ";
    "ä¸­æ–‡ç¼–ç¨‹è¯­è¨€";
    "å¤é›…ä½“è¯—è¯ç¼–ç¨‹";
  ] in
  
  List.iter (fun unicode_str ->
    let unicode_token = StringToken unicode_str in
    check bool ("Unicodeå­—ç¬¦ä¸²: " ^ unicode_str) true (TestHelpers.tokens_equal unicode_token (StringToken unicode_str))
  ) unicode_strings

let test_performance () =
  (* æµ‹è¯•å¤§é‡tokenåˆ›å»º *)
  let tokens = Array.init 1000 (fun i -> IntToken i) in
  check int "å¤§é‡tokenåˆ›å»º" 1000 (Array.length tokens);
  
  (* æµ‹è¯•tokenæ¯”è¾ƒæ€§èƒ½ *)
  let token1 = StringToken "performance_test" in
  let token2 = StringToken "performance_test" in
  let start_time = Sys.time () in
  for _i = 1 to 10000 do
    ignore (TestHelpers.tokens_equal token1 token2)
  done;
  let end_time = Sys.time () in
  let duration = end_time -. start_time in
  check bool "tokenæ¯”è¾ƒæ€§èƒ½æµ‹è¯•" true (duration < 1.0) (* åº”è¯¥åœ¨1ç§’å†…å®Œæˆ *)

(** æµ‹è¯•å¥—ä»¶å®šä¹‰ *)

let literal_tests = [
  test_case "literal_tokens" `Quick test_literal_tokens;
  test_case "identifier_tokens" `Quick test_identifier_tokens;
]

let keyword_tests = [
  test_case "basic_keywords" `Quick test_basic_keywords;
  test_case "semantic_keywords" `Quick test_semantic_keywords;
  test_case "exception_keywords" `Quick test_exception_keywords;
  test_case "module_keywords" `Quick test_module_keywords;
]

let wenyan_tests = [
  test_case "wenyan_keywords" `Quick test_wenyan_keywords;
  test_case "wenyan_extended_keywords" `Quick test_wenyan_extended_keywords;
]

let ancient_tests = [
  test_case "ancient_keywords" `Quick test_ancient_keywords;
  test_case "ancient_particles" `Quick test_ancient_particles;
  test_case "ancient_record_keywords" `Quick test_ancient_record_keywords;
]

let natural_language_tests = [
  test_case "natural_language_keywords" `Quick test_natural_language_keywords;
  test_case "natural_language_extended" `Quick test_natural_language_extended;
]

let type_tests = [
  test_case "type_keywords" `Quick test_type_keywords;
]

let poetry_tests = [
  test_case "poetry_keywords" `Quick test_poetry_keywords;
  test_case "poetry_forms" `Quick test_poetry_forms;
]

let operator_tests = [
  test_case "arithmetic_operators" `Quick test_arithmetic_operators;
  test_case "comparison_operators" `Quick test_comparison_operators;
  test_case "special_operators" `Quick test_special_operators;
]

let separator_tests = [
  test_case "ascii_separators" `Quick test_ascii_separators;
  test_case "array_separators" `Quick test_array_separators;
  test_case "chinese_punctuation" `Quick test_chinese_punctuation;
  test_case "chinese_arrows" `Quick test_chinese_arrows;
]

let special_tests = [
  test_case "special_tokens" `Quick test_special_tokens;
]

let position_tests = [
  test_case "position_creation" `Quick test_position_creation;
  test_case "position_equality" `Quick test_position_equality;
  test_case "positioned_token_creation" `Quick test_positioned_token_creation;
  test_case "positioned_token_equality" `Quick test_positioned_token_equality;
]

let error_tests = [
  test_case "lex_error" `Quick test_lex_error;
]

let show_tests = [
  test_case "token_show" `Quick test_token_show;
  test_case "position_show" `Quick test_position_show;
  test_case "positioned_token_show" `Quick test_positioned_token_show;
]

let boundary_tests = [
  test_case "boundary_conditions" `Quick test_boundary_conditions;
  test_case "unicode_handling" `Quick test_unicode_handling;
  test_case "performance" `Quick test_performance;
]

let () =
  run "éª†è¨€è¯æ³•ä»¤ç‰Œæ¨¡å—ç»¼åˆæµ‹è¯•" [
    "å­—é¢é‡tokens", literal_tests;
    "åŸºç¡€å…³é”®å­—", keyword_tests;
    "æ–‡è¨€æ–‡é£æ ¼å…³é”®å­—", wenyan_tests;
    "å¤é›…ä½“å…³é”®å­—", ancient_tests;
    "è‡ªç„¶è¯­è¨€å…³é”®å­—", natural_language_tests;
    "ç±»å‹å…³é”®å­—", type_tests;
    "è¯—è¯ç›¸å…³å…³é”®å­—", poetry_tests;
    "è¿ç®—ç¬¦tokens", operator_tests;
    "åˆ†éš”ç¬¦tokens", separator_tests;
    "ç‰¹æ®Štokens", special_tests;
    "ä½ç½®ä¿¡æ¯", position_tests;
    "é”™è¯¯å¤„ç†", error_tests;
    "æ˜¾ç¤ºåŠŸèƒ½", show_tests;
    "è¾¹ç•Œæ¡ä»¶å’Œæ€§èƒ½", boundary_tests;
  ]