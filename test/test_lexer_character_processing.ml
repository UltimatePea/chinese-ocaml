(** è¯æ³•åˆ†æå™¨å­—ç¬¦å¤„ç†æµ‹è¯• - éª†è¨€ç¼–è¯‘å™¨ *)

open Yyocamlc_lib.Lexer
open Yyocamlc_lib.Lexer.CharacterProcessing

(** è¾…åŠ©å‡½æ•°ï¼šæ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦åŒ…å«å­ä¸² *)
let contains_substring str substr =
  try
    let _ = Str.search_forward (Str.regexp (Str.quote substr)) str 0 in
    true
  with Not_found -> false

(** æµ‹è¯•ASCIIå­—ç¬¦ç¦ç”¨æ£€æŸ¥ *)
let test_ascii_forbidden_check () =
  let pos = { filename = "test.ly"; line = 1; column = 1 } in
  
  (* æµ‹è¯•è¢«ç¦ç”¨çš„ASCIIç¬¦å· *)
  let forbidden_chars = ['+'; '-'; '*'; '/'; '%'; '^'; '='; '<'; '>'; '.'; 
                        '('; ')'; '['; ']'; '{'; '}'; ','; ';'; ':'; '!'; 
                        '|'; '_'; '@'; '#'; '$'; '&'; '?'; '\''; '`'; '~'] in
  
  List.iter (fun c ->
    try
      check_ascii_forbidden c pos;
      Printf.printf "âš  è­¦å‘Šï¼šå­—ç¬¦ '%c' åº”è¯¥è¢«ç¦ç”¨ä½†æœªè¢«æ£€æµ‹åˆ°\n" c;
    with
    | LexError (msg, _) ->
      assert (contains_substring msg "ç¦");
      assert (contains_substring msg "ç”¨");
    | e -> 
      Printf.printf "æœªé¢„æœŸçš„å¼‚å¸¸ for '%c': %s\n" c (Printexc.to_string e);
      assert false
  ) forbidden_chars;
  
  print_endline "âœ“ ASCIIå­—ç¬¦ç¦ç”¨æ£€æŸ¥æµ‹è¯•é€šè¿‡"

(** æµ‹è¯•é˜¿æ‹‰ä¼¯æ•°å­—ç¦ç”¨æ£€æŸ¥ *)
let test_arabic_numbers_forbidden () =
  let pos = { filename = "test.ly"; line = 1; column = 1 } in
  
  (* æµ‹è¯•è¢«ç¦ç”¨çš„é˜¿æ‹‰ä¼¯æ•°å­— *)
  let digits = ['0'; '1'; '2'; '3'; '4'; '5'; '6'; '7'; '8'; '9'] in
  
  List.iter (fun c ->
    try
      check_ascii_forbidden c pos;
      Printf.printf "âš  è­¦å‘Šï¼šæ•°å­— '%c' åº”è¯¥è¢«ç¦ç”¨ä½†æœªè¢«æ£€æµ‹åˆ°\n" c;
    with
    | LexError (msg, _) ->
      assert (contains_substring msg "æ•°" || contains_substring msg "å­—");
    | e -> 
      Printf.printf "æœªé¢„æœŸçš„å¼‚å¸¸ for '%c': %s\n" c (Printexc.to_string e);
      assert false
  ) digits;
  
  print_endline "âœ“ é˜¿æ‹‰ä¼¯æ•°å­—ç¦ç”¨æ£€æŸ¥æµ‹è¯•é€šè¿‡"

(** æµ‹è¯•å…è®¸çš„å­—ç¬¦ *)
let test_allowed_characters () =
  let pos = { filename = "test.ly"; line = 1; column = 1 } in
  
  (* æµ‹è¯•åº”è¯¥è¢«å…è®¸çš„å­—ç¬¦ *)
  let allowed_chars = ['a'; 'A'; 'z'; 'Z'; ' '; '\t'; '\n'] in
  
  List.iter (fun c ->
    try
      check_ascii_forbidden c pos;
      (* åº”è¯¥ä¸æŠ›å‡ºå¼‚å¸¸ *)
    with
    | LexError (msg, _) ->
      Printf.printf "æ„å¤–é”™è¯¯ï¼šå­—ç¬¦ '%c' è¢«é”™è¯¯ç¦ç”¨: %s\n" c msg;
      assert false
    | e -> 
      Printf.printf "æœªé¢„æœŸçš„å¼‚å¸¸ for '%c': %s\n" c (Printexc.to_string e);
      (* å¯¹äºå…¶ä»–å¼‚å¸¸ï¼Œæˆ‘ä»¬æš‚æ—¶å…è®¸ï¼Œå› ä¸ºå¯èƒ½æ¶‰åŠæ›´å¤æ‚çš„å­—ç¬¦å¤„ç† *)
  ) allowed_chars;
  
  print_endline "âœ“ å…è®¸å­—ç¬¦æ£€æŸ¥æµ‹è¯•é€šè¿‡"

(** æµ‹è¯•å•å­—èŠ‚å­—ç¬¦tokenåŒ–ï¼ˆæˆåŠŸæƒ…å†µï¼‰ *)
let test_single_byte_tokenization_success () =
  try
    let state = Lexer_state.create_state "æµ‹è¯•ä¸­æ–‡a" in
    let pos = { filename = "test.ly"; line = 1; column = 1 } in
    
    (* æµ‹è¯•åˆæ³•çš„å•å­—èŠ‚å­—ç¬¦å¤„ç† *)
    let result = tokenize_single_byte_char state pos "a" in
    (* åŸºæœ¬éªŒè¯ï¼šåº”è¯¥è¿”å›æŸç§token *)
    assert (result != []);
    print_endline "âœ“ å•å­—èŠ‚å­—ç¬¦tokenåŒ–æˆåŠŸæµ‹è¯•é€šè¿‡"
  with
  | e ->
    Printf.printf "å•å­—èŠ‚å­—ç¬¦tokenåŒ–æµ‹è¯•å¼‚å¸¸: %s\n" (Printexc.to_string e);
    print_endline "âš  å•å­—èŠ‚å­—ç¬¦tokenåŒ–æµ‹è¯•éœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥"

(** æµ‹è¯•å•å­—èŠ‚å­—ç¬¦tokenåŒ–ï¼ˆé”™è¯¯æƒ…å†µï¼‰ *)
let test_single_byte_tokenization_error () =
  try
    let state = Lexer_state.create_state "test+" in
    let pos = { filename = "test.ly"; line = 1; column = 1 } in
    
    (* æµ‹è¯•ç¦ç”¨å­—ç¬¦åº”è¯¥æŠ›å‡ºå¼‚å¸¸ *)
    let _ = tokenize_single_byte_char state pos "+" in
    Printf.printf "âš  è­¦å‘Šï¼šç¦ç”¨å­—ç¬¦ '+' åº”è¯¥æŠ›å‡ºå¼‚å¸¸ä½†æœªæŠ›å‡º\n";
  with
  | LexError (msg, _) ->
    assert (String.contains msg 'ç¦');
    print_endline "âœ“ å•å­—èŠ‚å­—ç¬¦tokenåŒ–é”™è¯¯æ£€æµ‹æµ‹è¯•é€šè¿‡"
  | e ->
    Printf.printf "æœªé¢„æœŸçš„å¼‚å¸¸: %s\n" (Printexc.to_string e);
    print_endline "âš  å•å­—èŠ‚å­—ç¬¦tokenåŒ–é”™è¯¯æ£€æµ‹æµ‹è¯•éœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥"

(** æµ‹è¯•å­—ç¬¦å¤„ç†æ¨¡å—çš„ç»“æ„å®Œæ•´æ€§ *)
let test_character_processing_module () =
  (* éªŒè¯CharacterProcessingæ¨¡å—åŒ…å«å¿…è¦çš„å‡½æ•° *)
  let _ = check_ascii_forbidden in
  let _ = tokenize_single_byte_char in
  print_endline "âœ“ å­—ç¬¦å¤„ç†æ¨¡å—ç»“æ„å®Œæ•´æ€§æµ‹è¯•é€šè¿‡"

(** è¿è¡Œæ‰€æœ‰æµ‹è¯• *)
let () =
  print_endline "å¼€å§‹è¿è¡Œè¯æ³•åˆ†æå™¨å­—ç¬¦å¤„ç†æµ‹è¯•...";
  test_ascii_forbidden_check ();
  test_arabic_numbers_forbidden ();
  test_allowed_characters ();
  test_single_byte_tokenization_success ();
  test_single_byte_tokenization_error ();
  test_character_processing_module ();
  print_endline "ğŸ‰ æ‰€æœ‰è¯æ³•åˆ†æå™¨å­—ç¬¦å¤„ç†æµ‹è¯•å®Œæˆï¼"