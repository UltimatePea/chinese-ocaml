(** æ ¸å¿ƒæ¨¡å—æµ‹è¯•è¦†ç›–ç‡å¢å¼º - Phase 25 æµ‹è¯•è¦†ç›–ç‡æå‡
    
    æœ¬æµ‹è¯•æ¨¡å—ä¸“é—¨é’ˆå¯¹æ ¸å¿ƒç¼–è¯‘å™¨æ¨¡å—è¿›è¡ŒåŸºç¡€åŠŸèƒ½æµ‹è¯•ï¼Œ
    é‡ç‚¹æµ‹è¯•è¯æ³•åˆ†æã€è¯­æ³•åˆ†æå’ŒASTæ„å»ºçš„å…³é”®åŠŸèƒ½ã€‚
    
    æµ‹è¯•è¦†ç›–èŒƒå›´ï¼š
    - è¯æ³•åˆ†æå™¨åŸºç¡€åŠŸèƒ½
    - ASTèŠ‚ç‚¹æ„å»ºå’ŒéªŒè¯
    - ä¸­æ–‡å­—ç¬¦å¤„ç†
    - é”™è¯¯å¤„ç†æœºåˆ¶
    - Unicodeæ”¯æŒ
    
    @author éª†è¨€æŠ€æœ¯å€ºåŠ¡æ¸…ç†å›¢é˜Ÿ - Phase 25
    @version 1.0
    @since 2025-07-20 Issue #678 æ ¸å¿ƒæ¨¡å—æµ‹è¯•è¦†ç›–ç‡æå‡ *)

open Alcotest
open Yyocamlc_lib.Ast
open Yyocamlc_lib.Lexer

(** åŸºç¡€ASTæ„å»ºæµ‹è¯• *)
module AstConstructionTests = struct

  (** æµ‹è¯•å­—é¢é‡ASTæ„å»º *)
  let test_literal_ast_construction () =
    (* æµ‹è¯•æ•´æ•°å­—é¢é‡ *)
    let int_expr = make_int 42 in
    check (testable pp_expr equal_expr) "æ•´æ•°å­—é¢é‡AST" (LitExpr (IntLit 42)) int_expr;
    
    (* æµ‹è¯•å­—ç¬¦ä¸²å­—é¢é‡ *)
    let str_expr = make_string "ä½ å¥½ä¸–ç•Œ" in
    check (testable pp_expr equal_expr) "ä¸­æ–‡å­—ç¬¦ä¸²å­—é¢é‡AST" (LitExpr (StringLit "ä½ å¥½ä¸–ç•Œ")) str_expr;
    
    (* æµ‹è¯•å¸ƒå°”å­—é¢é‡ *)
    let bool_true = LitExpr (BoolLit true) in
    let bool_false = LitExpr (BoolLit false) in
    check (testable pp_expr equal_expr) "å¸ƒå°”trueå­—é¢é‡AST" (LitExpr (BoolLit true)) bool_true;
    check (testable pp_expr equal_expr) "å¸ƒå°”falseå­—é¢é‡AST" (LitExpr (BoolLit false)) bool_false

  (** æµ‹è¯•å˜é‡è¡¨è¾¾å¼æ„å»º *)
  let test_variable_expression_construction () =
    let var_exprs = [
      ("x", "ç®€å•å˜é‡");
      ("å˜é‡å", "ä¸­æ–‡å˜é‡å");
      ("var_123", "å¸¦æ•°å­—å˜é‡å");
      ("å‡½æ•°å_ä¸­è‹±æ··åˆ", "ä¸­è‹±æ··åˆå˜é‡å");
    ] in
    
    List.iter (fun (var_name, desc) ->
      let var_expr = VarExpr var_name in
      check (testable pp_expr equal_expr) desc (VarExpr var_name) var_expr
    ) var_exprs

  (** æµ‹è¯•äºŒå…ƒè¿ç®—è¡¨è¾¾å¼æ„å»º *)
  let test_binary_operation_construction () =
    let operations = [
      (Add, "åŠ æ³•");
      (Sub, "å‡æ³•");
      (Mul, "ä¹˜æ³•");
      (Div, "é™¤æ³•");
      (Eq, "ç›¸ç­‰æ¯”è¾ƒ");
      (Lt, "å°äºæ¯”è¾ƒ");
    ] in
    
    List.iter (fun (op, desc) ->
      let left = make_int 1 in
      let right = make_int 2 in
      let bin_expr = BinaryOpExpr (left, op, right) in
      let expected = BinaryOpExpr (LitExpr (IntLit 1), op, LitExpr (IntLit 2)) in
      check (testable pp_expr equal_expr) desc expected bin_expr
    ) operations

  (** æµ‹è¯•å¤åˆè¡¨è¾¾å¼æ„å»º *)
  let test_compound_expression_construction () =
    (* æµ‹è¯•å…ƒç»„è¡¨è¾¾å¼ *)
    let tuple_expr = TupleExpr [make_int 1; make_string "test"; LitExpr (BoolLit true)] in
    let expected_tuple = TupleExpr [LitExpr (IntLit 1); LitExpr (StringLit "test"); LitExpr (BoolLit true)] in
    check (testable pp_expr equal_expr) "å…ƒç»„è¡¨è¾¾å¼æ„å»º" expected_tuple tuple_expr;
    
    (* æµ‹è¯•åˆ—è¡¨è¡¨è¾¾å¼ *)
    let list_expr = ListExpr [make_int 1; make_int 2; make_int 3] in
    let expected_list = ListExpr [LitExpr (IntLit 1); LitExpr (IntLit 2); LitExpr (IntLit 3)] in
    check (testable pp_expr equal_expr) "åˆ—è¡¨è¡¨è¾¾å¼æ„å»º" expected_list list_expr;
    
    (* æµ‹è¯•å­—æ®µè®¿é—®è¡¨è¾¾å¼ *)
    let field_access = FieldAccessExpr (VarExpr "å¯¹è±¡", "å­—æ®µ") in
    check (testable pp_expr equal_expr) "å­—æ®µè®¿é—®è¡¨è¾¾å¼æ„å»º" field_access field_access

end

(** è¯æ³•åˆ†æå™¨åŸºç¡€æµ‹è¯• *)
module LexerBasicTests = struct

  (** æµ‹è¯•æ•°å­—tokenè¯†åˆ« *)
  let test_number_token_recognition () =
    let numbers = [42; 0; 123; 999] in
    List.iter (fun num ->
      let pos = { line = 1; column = 1; filename = "test" } in
      let token = IntToken num in
      let token_with_pos = (token, pos) in
      check (testable pp_token equal_token) (Printf.sprintf "æ•°å­—%d tokenè¯†åˆ«" num) token (fst token_with_pos)
    ) numbers

  (** æµ‹è¯•å­—ç¬¦ä¸²tokenè¯†åˆ« *)
  let test_string_token_recognition () =
    let strings = ["hello"; "ä½ å¥½"; "worldä¸–ç•Œ"; "æµ‹è¯•string"] in
    List.iter (fun str ->
      let pos = { line = 1; column = 1; filename = "test" } in
      let token = StringToken str in
      let token_with_pos = (token, pos) in
      check (testable pp_token equal_token) (Printf.sprintf "å­—ç¬¦ä¸²'%s' tokenè¯†åˆ«" str) token (fst token_with_pos)
    ) strings

  (** æµ‹è¯•æ ‡è¯†ç¬¦tokenè¯†åˆ« *)
  let test_identifier_token_recognition () =
    let identifiers = ["x"; "å˜é‡"; "func_name"; "ä¸­æ–‡_æ ‡è¯†ç¬¦"] in
    List.iter (fun id ->
      let pos = { line = 1; column = 1; filename = "test" } in
      let token = QuotedIdentifierToken id in
      let token_with_pos = (token, pos) in
      check (testable pp_token equal_token) (Printf.sprintf "æ ‡è¯†ç¬¦'%s' tokenè¯†åˆ«" id) token (fst token_with_pos)
    ) identifiers

  (** æµ‹è¯•è¿ç®—ç¬¦tokenè¯†åˆ« *)
  let test_operator_token_recognition () =
    let operators = [
      (Plus, "+");
      (Minus, "-");
      (Multiply, "*");
      (Assign, "=");
      (LeftParen, "(");
      (RightParen, ")");
    ] in
    
    List.iter (fun (token, desc) ->
      let pos = { line = 1; column = 1; filename = "test" } in
      let token_with_pos = (token, pos) in
      check (testable pp_token equal_token) (Printf.sprintf "è¿ç®—ç¬¦'%s' tokenè¯†åˆ«" desc) token (fst token_with_pos)
    ) operators

end

(** Unicodeå’Œä¸­æ–‡å­—ç¬¦å¤„ç†æµ‹è¯• *)
module UnicodeHandlingTests = struct

  (** æµ‹è¯•ä¸­æ–‡å­—ç¬¦ä¸²å¤„ç† *)
  let test_chinese_string_handling () =
    let chinese_strings = [
      "æ˜¥çœ ä¸è§‰æ™“";
      "å¤„å¤„é—»å•¼é¸Ÿ";
      "å¤œæ¥é£é›¨å£°";
      "èŠ±è½çŸ¥å¤šå°‘";
    ] in
    
    List.iter (fun text ->
      let str_expr = make_string text in
      check (testable pp_expr equal_expr) (Printf.sprintf "ä¸­æ–‡å­—ç¬¦ä¸²'%s'å¤„ç†" text) 
        (LitExpr (StringLit text)) str_expr
    ) chinese_strings

  (** æµ‹è¯•æ··åˆå­—ç¬¦å¤„ç† *)
  let test_mixed_character_handling () =
    let mixed_strings = [
      "Helloä¸–ç•Œ";
      "æµ‹è¯•123";
      "ä¸­Englishæ–‡";
      "æ•°å­—456æ±‰å­—";
    ] in
    
    List.iter (fun text ->
      let str_expr = make_string text in
      check (testable pp_expr equal_expr) (Printf.sprintf "æ··åˆå­—ç¬¦'%s'å¤„ç†" text)
        (LitExpr (StringLit text)) str_expr
    ) mixed_strings

  (** æµ‹è¯•Unicodeè¡¨æƒ…ç¬¦å·å¤„ç† *)
  let test_unicode_emoji_handling () =
    let emoji_strings = [
      "ğŸŒ¸æ˜¥å¤©";
      "ğŸŒ™æœˆäº®";
      "ğŸ”¥ç«ç„°";
      "ğŸ’»ä»£ç ";
    ] in
    
    List.iter (fun text ->
      let str_expr = make_string text in
      check (testable pp_expr equal_expr) (Printf.sprintf "è¡¨æƒ…ç¬¦å·'%s'å¤„ç†" text)
        (LitExpr (StringLit text)) str_expr
    ) emoji_strings

end

(** é”™è¯¯å¤„ç†å’Œè¾¹ç•Œæ¡ä»¶æµ‹è¯• *)
module ErrorHandlingTests = struct

  (** æµ‹è¯•ç©ºå­—ç¬¦ä¸²å¤„ç† *)
  let test_empty_string_handling () =
    let empty_expr = make_string "" in
    check (testable pp_expr equal_expr) "ç©ºå­—ç¬¦ä¸²å¤„ç†" (LitExpr (StringLit "")) empty_expr

  (** æµ‹è¯•é›¶å€¼å¤„ç† *)
  let test_zero_value_handling () =
    let zero_expr = make_int 0 in
    check (testable pp_expr equal_expr) "é›¶å€¼å¤„ç†" (LitExpr (IntLit 0)) zero_expr

  (** æµ‹è¯•è´Ÿæ•°å¤„ç† *)
  let test_negative_number_handling () =
    let neg_expr = LitExpr (IntLit (-42)) in
    check (testable pp_expr equal_expr) "è´Ÿæ•°å¤„ç†" (LitExpr (IntLit (-42))) neg_expr

  (** æµ‹è¯•é•¿å­—ç¬¦ä¸²å¤„ç† *)
  let test_long_string_handling () =
    let long_string = String.make 1000 'a' in
    let long_expr = make_string long_string in
    check (testable pp_expr equal_expr) "é•¿å­—ç¬¦ä¸²å¤„ç†" (LitExpr (StringLit long_string)) long_expr

end

(** æ€§èƒ½å’Œå‹åŠ›æµ‹è¯• *)
module PerformanceTests = struct

  (** æµ‹è¯•å¤§é‡è¡¨è¾¾å¼æ„å»º *)
  let test_bulk_expression_construction () =
    let start_time = Sys.time () in
    
    (* æ„å»º1000ä¸ªè¡¨è¾¾å¼ *)
    let expressions = List.init 1000 (fun i -> make_int i) in
    
    let construction_time = Sys.time () -. start_time in
    
    (* éªŒè¯æ‰€æœ‰è¡¨è¾¾å¼éƒ½è¢«æ­£ç¡®æ„å»º *)
    List.iteri (fun i expr ->
      check (testable pp_expr equal_expr) (Printf.sprintf "æ‰¹é‡è¡¨è¾¾å¼%dæ„å»º" i) 
        (LitExpr (IntLit i)) expr
    ) expressions;
    
    (* æ€§èƒ½è¦æ±‚ï¼šæ„å»ºæ—¶é—´åº”åœ¨åˆç†èŒƒå›´å†… *)
    check bool "æ‰¹é‡è¡¨è¾¾å¼æ„å»ºæ€§èƒ½" true (construction_time < 1.0);
    
    Printf.printf "1000ä¸ªè¡¨è¾¾å¼æ„å»ºæ—¶é—´: %.6f ç§’\n" construction_time

  (** æµ‹è¯•æ·±åº¦åµŒå¥—è¡¨è¾¾å¼ *)
  let test_deep_nested_expressions () =
    (* åˆ›å»ºæ·±åº¦åµŒå¥—çš„äºŒå…ƒè¿ç®—è¡¨è¾¾å¼ *)
    let rec create_nested_expr depth =
      if depth <= 0 then
        make_int 1
      else
        BinaryOpExpr (create_nested_expr (depth - 1), Add, make_int depth)
    in
    
    let deep_expr = create_nested_expr 10 in
    
    (* éªŒè¯è¡¨è¾¾å¼ç»“æ„ *)
    let rec count_depth expr =
      match expr with
      | BinaryOpExpr (left, _, _) -> 1 + count_depth left
      | _ -> 0
    in
    
    let actual_depth = count_depth deep_expr in
    check int "æ·±åº¦åµŒå¥—è¡¨è¾¾å¼æ·±åº¦" 10 actual_depth

  (** æµ‹è¯•å†…å­˜ä½¿ç”¨ *)
  let test_memory_usage () =
    let gc_stats_before = Gc.stat () in
    
    (* åˆ›å»ºå’Œé”€æ¯å¤§é‡è¡¨è¾¾å¼ *)
    for _i = 1 to 1000 do
      let expr = BinaryOpExpr (make_int 1, Add, make_int 2) in
      ignore expr
    done;
    
    Gc.full_major ();
    let gc_stats_after = Gc.stat () in
    
    let memory_increase = gc_stats_after.live_words - gc_stats_before.live_words in
    
    (* å†…å­˜å¢é•¿åº”è¯¥åœ¨åˆç†èŒƒå›´å†… *)
    check bool "å†…å­˜ä½¿ç”¨åˆç†" true (memory_increase < 50000);
    
    Printf.printf "å†…å­˜å¢é•¿: %d words\n" memory_increase

end

(** æµ‹è¯•å¥—ä»¶æ³¨å†Œ *)
let test_suite = [
  "ASTæ„å»ºæµ‹è¯•", [
    test_case "å­—é¢é‡ASTæ„å»º" `Quick AstConstructionTests.test_literal_ast_construction;
    test_case "å˜é‡è¡¨è¾¾å¼æ„å»º" `Quick AstConstructionTests.test_variable_expression_construction;
    test_case "äºŒå…ƒè¿ç®—æ„å»º" `Quick AstConstructionTests.test_binary_operation_construction;
    test_case "å¤åˆè¡¨è¾¾å¼æ„å»º" `Quick AstConstructionTests.test_compound_expression_construction;
  ];
  
  "è¯æ³•åˆ†æå™¨åŸºç¡€", [
    test_case "æ•°å­—tokenè¯†åˆ«" `Quick LexerBasicTests.test_number_token_recognition;
    test_case "å­—ç¬¦ä¸²tokenè¯†åˆ«" `Quick LexerBasicTests.test_string_token_recognition;
    test_case "æ ‡è¯†ç¬¦tokenè¯†åˆ«" `Quick LexerBasicTests.test_identifier_token_recognition;
    test_case "è¿ç®—ç¬¦tokenè¯†åˆ«" `Quick LexerBasicTests.test_operator_token_recognition;
  ];
  
  "Unicodeå¤„ç†", [
    test_case "ä¸­æ–‡å­—ç¬¦ä¸²å¤„ç†" `Quick UnicodeHandlingTests.test_chinese_string_handling;
    test_case "æ··åˆå­—ç¬¦å¤„ç†" `Quick UnicodeHandlingTests.test_mixed_character_handling;
    test_case "Unicodeè¡¨æƒ…ç¬¦å·" `Quick UnicodeHandlingTests.test_unicode_emoji_handling;
  ];
  
  "é”™è¯¯å¤„ç†", [
    test_case "ç©ºå­—ç¬¦ä¸²å¤„ç†" `Quick ErrorHandlingTests.test_empty_string_handling;
    test_case "é›¶å€¼å¤„ç†" `Quick ErrorHandlingTests.test_zero_value_handling;
    test_case "è´Ÿæ•°å¤„ç†" `Quick ErrorHandlingTests.test_negative_number_handling;
    test_case "é•¿å­—ç¬¦ä¸²å¤„ç†" `Quick ErrorHandlingTests.test_long_string_handling;
  ];
  
  "æ€§èƒ½æµ‹è¯•", [
    test_case "æ‰¹é‡è¡¨è¾¾å¼æ„å»º" `Quick PerformanceTests.test_bulk_expression_construction;
    test_case "æ·±åº¦åµŒå¥—è¡¨è¾¾å¼" `Quick PerformanceTests.test_deep_nested_expressions;
    test_case "å†…å­˜ä½¿ç”¨æµ‹è¯•" `Quick PerformanceTests.test_memory_usage;
  ];
]

(** è¿è¡Œæ‰€æœ‰æµ‹è¯• *)
let () = 
  Printf.printf "éª†è¨€æ ¸å¿ƒæ¨¡å—æµ‹è¯•è¦†ç›–ç‡å¢å¼º - Phase 25\n";
  Printf.printf "======================================================\n";
  run "Core Coverage Enhanced Tests" test_suite